<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>R for Psych</title>
  <meta name="description" content="An introduction to data management and analysis for psychological research using R.">
  <meta name="generator" content="bookdown 0.6 and GitBook 2.6.7">

  <meta property="og:title" content="R for Psych" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://glennwilliams.me/r4psych/" />
  
  <meta property="og:description" content="An introduction to data management and analysis for psychological research using R." />
  <meta name="github-repo" content="gpwilliams/r4psych" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="R for Psych" />
  
  <meta name="twitter:description" content="An introduction to data management and analysis for psychological research using R." />
  

<meta name="author" content="Glenn Williams">


<meta name="date" content="2018-04-25">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="simulation-and-calculating-power.html">
<link rel="next" href="creating-reproducible-documents.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-117777827-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-117777827-1');
</script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">R for Psych</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface &amp; Overview</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#installation-and-setup"><i class="fa fa-check"></i><b>1.1</b> Installation and Setup</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#working-directory-and-file-paths"><i class="fa fa-check"></i><b>1.2</b> Working Directory and File Paths</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#packages"><i class="fa fa-check"></i><b>1.3</b> Packages</a></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#objects-and-functions"><i class="fa fa-check"></i><b>1.4</b> Objects and Functions</a></li>
<li class="chapter" data-level="1.5" data-path="introduction.html"><a href="introduction.html#creating-and-accessing-data"><i class="fa fa-check"></i><b>1.5</b> Creating and Accessing Data</a></li>
<li class="chapter" data-level="1.6" data-path="introduction.html"><a href="introduction.html#good-practice"><i class="fa fa-check"></i><b>1.6</b> Good Practice</a><ul>
<li class="chapter" data-level="1.6.1" data-path="introduction.html"><a href="introduction.html#data-checking-tips"><i class="fa fa-check"></i><b>1.6.1</b> Data Checking Tips</a></li>
<li class="chapter" data-level="1.6.2" data-path="introduction.html"><a href="introduction.html#style"><i class="fa fa-check"></i><b>1.6.2</b> Style</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="introduction.html"><a href="introduction.html#exercises"><i class="fa fa-check"></i><b>1.7</b> Exercises</a><ul>
<li class="chapter" data-level="1.7.1" data-path="introduction.html"><a href="introduction.html#question-1"><i class="fa fa-check"></i><b>1.7.1</b> Question 1</a></li>
<li class="chapter" data-level="1.7.2" data-path="introduction.html"><a href="introduction.html#question-2"><i class="fa fa-check"></i><b>1.7.2</b> Question 2</a></li>
<li class="chapter" data-level="1.7.3" data-path="introduction.html"><a href="introduction.html#question-3"><i class="fa fa-check"></i><b>1.7.3</b> Question 3</a></li>
<li class="chapter" data-level="1.7.4" data-path="introduction.html"><a href="introduction.html#question-4"><i class="fa fa-check"></i><b>1.7.4</b> Question 4</a></li>
<li class="chapter" data-level="1.7.5" data-path="introduction.html"><a href="introduction.html#question-5"><i class="fa fa-check"></i><b>1.7.5</b> Question 5</a></li>
<li class="chapter" data-level="1.7.6" data-path="introduction.html"><a href="introduction.html#question-6"><i class="fa fa-check"></i><b>1.7.6</b> Question 6</a></li>
<li class="chapter" data-level="1.7.7" data-path="introduction.html"><a href="introduction.html#question-7"><i class="fa fa-check"></i><b>1.7.7</b> Question 7</a></li>
<li class="chapter" data-level="1.7.8" data-path="introduction.html"><a href="introduction.html#question-8"><i class="fa fa-check"></i><b>1.7.8</b> Question 8</a></li>
<li class="chapter" data-level="1.7.9" data-path="introduction.html"><a href="introduction.html#question-9"><i class="fa fa-check"></i><b>1.7.9</b> Question 9</a></li>
<li class="chapter" data-level="1.7.10" data-path="introduction.html"><a href="introduction.html#question-10"><i class="fa fa-check"></i><b>1.7.10</b> Question 10</a></li>
<li class="chapter" data-level="1.7.11" data-path="introduction.html"><a href="introduction.html#question-11"><i class="fa fa-check"></i><b>1.7.11</b> Question 11</a></li>
<li class="chapter" data-level="1.7.12" data-path="introduction.html"><a href="introduction.html#question-12"><i class="fa fa-check"></i><b>1.7.12</b> Question 12</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="data-visualisation-1.html"><a href="data-visualisation-1.html"><i class="fa fa-check"></i><b>2</b> Data Visualisation 1</a><ul>
<li class="chapter" data-level="2.1" data-path="data-visualisation-1.html"><a href="data-visualisation-1.html#getting-started"><i class="fa fa-check"></i><b>2.1</b> Getting Started</a><ul>
<li class="chapter" data-level="2.1.1" data-path="data-visualisation-1.html"><a href="data-visualisation-1.html#the-star-wars-tibble"><i class="fa fa-check"></i><b>2.1.1</b> The Star Wars Tibble</a></li>
<li class="chapter" data-level="2.1.2" data-path="data-visualisation-1.html"><a href="data-visualisation-1.html#plotting-in-ggplot2"><i class="fa fa-check"></i><b>2.1.2</b> Plotting in ggplot2</a></li>
<li class="chapter" data-level="2.1.3" data-path="data-visualisation-1.html"><a href="data-visualisation-1.html#cleaning-before-plotting"><i class="fa fa-check"></i><b>2.1.3</b> Cleaning Before Plotting</a></li>
<li class="chapter" data-level="2.1.4" data-path="data-visualisation-1.html"><a href="data-visualisation-1.html#changing-your-aesthetics"><i class="fa fa-check"></i><b>2.1.4</b> Changing Your Aesthetics</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="data-visualisation-1.html"><a href="data-visualisation-1.html#exploring-different-geoms"><i class="fa fa-check"></i><b>2.2</b> Exploring Different Geoms</a><ul>
<li class="chapter" data-level="2.2.1" data-path="data-visualisation-1.html"><a href="data-visualisation-1.html#bar-plots"><i class="fa fa-check"></i><b>2.2.1</b> Bar Plots</a></li>
<li class="chapter" data-level="2.2.2" data-path="data-visualisation-1.html"><a href="data-visualisation-1.html#box-plots"><i class="fa fa-check"></i><b>2.2.2</b> Box Plots</a></li>
<li class="chapter" data-level="2.2.3" data-path="data-visualisation-1.html"><a href="data-visualisation-1.html#violin-plots"><i class="fa fa-check"></i><b>2.2.3</b> Violin Plots</a></li>
<li class="chapter" data-level="2.2.4" data-path="data-visualisation-1.html"><a href="data-visualisation-1.html#density-plots"><i class="fa fa-check"></i><b>2.2.4</b> Density Plots</a></li>
<li class="chapter" data-level="2.2.5" data-path="data-visualisation-1.html"><a href="data-visualisation-1.html#histograms"><i class="fa fa-check"></i><b>2.2.5</b> Histograms</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="data-visualisation-1.html"><a href="data-visualisation-1.html#exercises-1"><i class="fa fa-check"></i><b>2.3</b> Exercises</a><ul>
<li class="chapter" data-level="2.3.1" data-path="data-visualisation-1.html"><a href="data-visualisation-1.html#main-exercises"><i class="fa fa-check"></i><b>2.3.1</b> Main Exercises</a></li>
<li class="chapter" data-level="2.3.2" data-path="data-visualisation-1.html"><a href="data-visualisation-1.html#question-1-1"><i class="fa fa-check"></i><b>2.3.2</b> Question 1</a></li>
<li class="chapter" data-level="2.3.3" data-path="data-visualisation-1.html"><a href="data-visualisation-1.html#question-2-1"><i class="fa fa-check"></i><b>2.3.3</b> Question 2</a></li>
<li class="chapter" data-level="2.3.4" data-path="data-visualisation-1.html"><a href="data-visualisation-1.html#question-3-1"><i class="fa fa-check"></i><b>2.3.4</b> Question 3</a></li>
<li class="chapter" data-level="2.3.5" data-path="data-visualisation-1.html"><a href="data-visualisation-1.html#question-4-1"><i class="fa fa-check"></i><b>2.3.5</b> Question 4</a></li>
<li class="chapter" data-level="2.3.6" data-path="data-visualisation-1.html"><a href="data-visualisation-1.html#question-5-1"><i class="fa fa-check"></i><b>2.3.6</b> Question 5</a></li>
<li class="chapter" data-level="2.3.7" data-path="data-visualisation-1.html"><a href="data-visualisation-1.html#question-6-1"><i class="fa fa-check"></i><b>2.3.7</b> Question 6</a></li>
<li class="chapter" data-level="2.3.8" data-path="data-visualisation-1.html"><a href="data-visualisation-1.html#question-7-1"><i class="fa fa-check"></i><b>2.3.8</b> Question 7</a></li>
<li class="chapter" data-level="2.3.9" data-path="data-visualisation-1.html"><a href="data-visualisation-1.html#question-8-1"><i class="fa fa-check"></i><b>2.3.9</b> Question 8</a></li>
<li class="chapter" data-level="2.3.10" data-path="data-visualisation-1.html"><a href="data-visualisation-1.html#question-9-1"><i class="fa fa-check"></i><b>2.3.10</b> Question 9</a></li>
<li class="chapter" data-level="2.3.11" data-path="data-visualisation-1.html"><a href="data-visualisation-1.html#question-10-1"><i class="fa fa-check"></i><b>2.3.11</b> Question 10</a></li>
<li class="chapter" data-level="2.3.12" data-path="data-visualisation-1.html"><a href="data-visualisation-1.html#additional-exercise"><i class="fa fa-check"></i><b>2.3.12</b> Additional Exercise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data-visualisation-2.html"><a href="data-visualisation-2.html"><i class="fa fa-check"></i><b>3</b> Data Visualisation 2</a><ul>
<li class="chapter" data-level="3.1" data-path="data-visualisation-2.html"><a href="data-visualisation-2.html#customising-your-plots"><i class="fa fa-check"></i><b>3.1</b> Customising Your Plots</a></li>
<li class="chapter" data-level="3.2" data-path="data-visualisation-2.html"><a href="data-visualisation-2.html#pirate-plots"><i class="fa fa-check"></i><b>3.2</b> Pirate Plots</a></li>
<li class="chapter" data-level="3.3" data-path="data-visualisation-2.html"><a href="data-visualisation-2.html#faceting"><i class="fa fa-check"></i><b>3.3</b> Faceting</a><ul>
<li class="chapter" data-level="3.3.1" data-path="data-visualisation-2.html"><a href="data-visualisation-2.html#facet-wrap"><i class="fa fa-check"></i><b>3.3.1</b> Facet Wrap</a></li>
<li class="chapter" data-level="3.3.2" data-path="data-visualisation-2.html"><a href="data-visualisation-2.html#facet-grid"><i class="fa fa-check"></i><b>3.3.2</b> Facet Grid</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="data-visualisation-2.html"><a href="data-visualisation-2.html#calculating-statisitcs-in-ggplot2"><i class="fa fa-check"></i><b>3.4</b> Calculating Statisitcs in ggplot2</a><ul>
<li class="chapter" data-level="3.4.1" data-path="data-visualisation-2.html"><a href="data-visualisation-2.html#means-and-error-bars"><i class="fa fa-check"></i><b>3.4.1</b> Means and Error Bars</a></li>
<li class="chapter" data-level="3.4.2" data-path="data-visualisation-2.html"><a href="data-visualisation-2.html#model-fits"><i class="fa fa-check"></i><b>3.4.2</b> Model Fits</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="data-visualisation-2.html"><a href="data-visualisation-2.html#combining-plots"><i class="fa fa-check"></i><b>3.5</b> Combining Plots</a></li>
<li class="chapter" data-level="3.6" data-path="data-visualisation-2.html"><a href="data-visualisation-2.html#saving-plots"><i class="fa fa-check"></i><b>3.6</b> Saving Plots</a></li>
<li class="chapter" data-level="3.7" data-path="data-visualisation-2.html"><a href="data-visualisation-2.html#exercises-2"><i class="fa fa-check"></i><b>3.7</b> Exercises</a><ul>
<li class="chapter" data-level="3.7.1" data-path="data-visualisation-2.html"><a href="data-visualisation-2.html#main-exercises-1"><i class="fa fa-check"></i><b>3.7.1</b> Main Exercises</a></li>
<li class="chapter" data-level="3.7.2" data-path="data-visualisation-2.html"><a href="data-visualisation-2.html#question-1-2"><i class="fa fa-check"></i><b>3.7.2</b> Question 1</a></li>
<li class="chapter" data-level="3.7.3" data-path="data-visualisation-2.html"><a href="data-visualisation-2.html#question-2-2"><i class="fa fa-check"></i><b>3.7.3</b> Question 2</a></li>
<li class="chapter" data-level="3.7.4" data-path="data-visualisation-2.html"><a href="data-visualisation-2.html#question-3-2"><i class="fa fa-check"></i><b>3.7.4</b> Question 3</a></li>
<li class="chapter" data-level="3.7.5" data-path="data-visualisation-2.html"><a href="data-visualisation-2.html#question-4-2"><i class="fa fa-check"></i><b>3.7.5</b> Question 4</a></li>
<li class="chapter" data-level="3.7.6" data-path="data-visualisation-2.html"><a href="data-visualisation-2.html#question-5-2"><i class="fa fa-check"></i><b>3.7.6</b> Question 5</a></li>
<li class="chapter" data-level="3.7.7" data-path="data-visualisation-2.html"><a href="data-visualisation-2.html#question-6-2"><i class="fa fa-check"></i><b>3.7.7</b> Question 6</a></li>
<li class="chapter" data-level="3.7.8" data-path="data-visualisation-2.html"><a href="data-visualisation-2.html#question-7-2"><i class="fa fa-check"></i><b>3.7.8</b> Question 7</a></li>
<li class="chapter" data-level="3.7.9" data-path="data-visualisation-2.html"><a href="data-visualisation-2.html#question-8-2"><i class="fa fa-check"></i><b>3.7.9</b> Question 8</a></li>
<li class="chapter" data-level="3.7.10" data-path="data-visualisation-2.html"><a href="data-visualisation-2.html#question-9-2"><i class="fa fa-check"></i><b>3.7.10</b> Question 9</a></li>
<li class="chapter" data-level="3.7.11" data-path="data-visualisation-2.html"><a href="data-visualisation-2.html#additional-exercise-1"><i class="fa fa-check"></i><b>3.7.11</b> Additional Exercise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="data-manipulation-1.html"><a href="data-manipulation-1.html"><i class="fa fa-check"></i><b>4</b> Data Manipulation 1</a><ul>
<li class="chapter" data-level="4.1" data-path="data-manipulation-1.html"><a href="data-manipulation-1.html#getting-started-1"><i class="fa fa-check"></i><b>4.1</b> Getting Started</a></li>
<li class="chapter" data-level="4.2" data-path="data-manipulation-1.html"><a href="data-manipulation-1.html#data-formats"><i class="fa fa-check"></i><b>4.2</b> Data Formats</a><ul>
<li class="chapter" data-level="4.2.1" data-path="data-manipulation-1.html"><a href="data-manipulation-1.html#loading-data"><i class="fa fa-check"></i><b>4.2.1</b> Loading Data</a></li>
<li class="chapter" data-level="4.2.2" data-path="data-manipulation-1.html"><a href="data-manipulation-1.html#wide-and-long-data"><i class="fa fa-check"></i><b>4.2.2</b> Wide and Long Data</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="data-manipulation-1.html"><a href="data-manipulation-1.html#reformatting-data"><i class="fa fa-check"></i><b>4.3</b> Reformatting Data</a><ul>
<li class="chapter" data-level="4.3.1" data-path="data-manipulation-1.html"><a href="data-manipulation-1.html#gathering-data"><i class="fa fa-check"></i><b>4.3.1</b> Gathering Data</a></li>
<li class="chapter" data-level="4.3.2" data-path="data-manipulation-1.html"><a href="data-manipulation-1.html#separating-columns"><i class="fa fa-check"></i><b>4.3.2</b> Separating Columns</a></li>
<li class="chapter" data-level="4.3.3" data-path="data-manipulation-1.html"><a href="data-manipulation-1.html#spreading-data"><i class="fa fa-check"></i><b>4.3.3</b> Spreading Data</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="data-manipulation-1.html"><a href="data-manipulation-1.html#joins"><i class="fa fa-check"></i><b>4.4</b> Joins</a><ul>
<li class="chapter" data-level="4.4.1" data-path="data-manipulation-1.html"><a href="data-manipulation-1.html#mutating-joins"><i class="fa fa-check"></i><b>4.4.1</b> Mutating Joins</a></li>
<li class="chapter" data-level="4.4.2" data-path="data-manipulation-1.html"><a href="data-manipulation-1.html#filtering-joins"><i class="fa fa-check"></i><b>4.4.2</b> Filtering Joins</a></li>
<li class="chapter" data-level="4.4.3" data-path="data-manipulation-1.html"><a href="data-manipulation-1.html#binding-joins"><i class="fa fa-check"></i><b>4.4.3</b> Binding Joins</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="data-manipulation-1.html"><a href="data-manipulation-1.html#checking-for-unique-and-duplicate-information"><i class="fa fa-check"></i><b>4.5</b> Checking for Unique and Duplicate Information</a></li>
<li class="chapter" data-level="4.6" data-path="data-manipulation-1.html"><a href="data-manipulation-1.html#exercises-3"><i class="fa fa-check"></i><b>4.6</b> Exercises</a><ul>
<li class="chapter" data-level="4.6.1" data-path="data-manipulation-1.html"><a href="data-manipulation-1.html#introduction-and-setup"><i class="fa fa-check"></i><b>4.6.1</b> Introduction and Setup</a></li>
<li class="chapter" data-level="4.6.2" data-path="data-manipulation-1.html"><a href="data-manipulation-1.html#long-and-wide-data"><i class="fa fa-check"></i><b>4.6.2</b> Long and Wide Data</a></li>
<li class="chapter" data-level="4.6.3" data-path="data-manipulation-1.html"><a href="data-manipulation-1.html#uniting-and-separating-columns"><i class="fa fa-check"></i><b>4.6.3</b> Uniting and Separating Columns</a></li>
<li class="chapter" data-level="4.6.4" data-path="data-manipulation-1.html"><a href="data-manipulation-1.html#mutating-joins-1"><i class="fa fa-check"></i><b>4.6.4</b> Mutating Joins</a></li>
<li class="chapter" data-level="4.6.5" data-path="data-manipulation-1.html"><a href="data-manipulation-1.html#filtering-joins-1"><i class="fa fa-check"></i><b>4.6.5</b> Filtering Joins</a></li>
<li class="chapter" data-level="4.6.6" data-path="data-manipulation-1.html"><a href="data-manipulation-1.html#binding-joins-1"><i class="fa fa-check"></i><b>4.6.6</b> Binding Joins</a></li>
<li class="chapter" data-level="4.6.7" data-path="data-manipulation-1.html"><a href="data-manipulation-1.html#checking-for-duplicates"><i class="fa fa-check"></i><b>4.6.7</b> Checking for Duplicates</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="data-manipulation-2.html"><a href="data-manipulation-2.html"><i class="fa fa-check"></i><b>5</b> Data Manipulation 2</a><ul>
<li class="chapter" data-level="5.1" data-path="data-manipulation-2.html"><a href="data-manipulation-2.html#getting-started-2"><i class="fa fa-check"></i><b>5.1</b> Getting Started</a></li>
<li class="chapter" data-level="5.2" data-path="data-manipulation-2.html"><a href="data-manipulation-2.html#understanding-our-data"><i class="fa fa-check"></i><b>5.2</b> Understanding our Data</a></li>
<li class="chapter" data-level="5.3" data-path="data-manipulation-2.html"><a href="data-manipulation-2.html#preparing-our-data"><i class="fa fa-check"></i><b>5.3</b> Preparing our Data</a></li>
<li class="chapter" data-level="5.4" data-path="data-manipulation-2.html"><a href="data-manipulation-2.html#selecting-columns"><i class="fa fa-check"></i><b>5.4</b> Selecting Columns</a><ul>
<li class="chapter" data-level="5.4.1" data-path="data-manipulation-2.html"><a href="data-manipulation-2.html#renaming-and-reordering-columns"><i class="fa fa-check"></i><b>5.4.1</b> Renaming and Reordering Columns</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="data-manipulation-2.html"><a href="data-manipulation-2.html#creating-and-changing-columns"><i class="fa fa-check"></i><b>5.5</b> Creating and Changing Columns</a></li>
<li class="chapter" data-level="5.6" data-path="data-manipulation-2.html"><a href="data-manipulation-2.html#filtering-to-observations"><i class="fa fa-check"></i><b>5.6</b> Filtering to Observations</a><ul>
<li class="chapter" data-level="5.6.1" data-path="data-manipulation-2.html"><a href="data-manipulation-2.html#filtering-with-logical-operations"><i class="fa fa-check"></i><b>5.6.1</b> Filtering with Logical Operations</a></li>
<li class="chapter" data-level="5.6.2" data-path="data-manipulation-2.html"><a href="data-manipulation-2.html#combining-filtering-criteria"><i class="fa fa-check"></i><b>5.6.2</b> Combining Filtering Criteria</a></li>
<li class="chapter" data-level="5.6.3" data-path="data-manipulation-2.html"><a href="data-manipulation-2.html#removing-by-ceriteria"><i class="fa fa-check"></i><b>5.6.3</b> Removing by Ceriteria</a></li>
<li class="chapter" data-level="5.6.4" data-path="data-manipulation-2.html"><a href="data-manipulation-2.html#handling-nas"><i class="fa fa-check"></i><b>5.6.4</b> Handling NAs</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="data-manipulation-2.html"><a href="data-manipulation-2.html#arranging-data"><i class="fa fa-check"></i><b>5.7</b> Arranging Data</a></li>
<li class="chapter" data-level="5.8" data-path="data-manipulation-2.html"><a href="data-manipulation-2.html#summarising-data"><i class="fa fa-check"></i><b>5.8</b> Summarising Data</a></li>
<li class="chapter" data-level="5.9" data-path="data-manipulation-2.html"><a href="data-manipulation-2.html#grouping-data"><i class="fa fa-check"></i><b>5.9</b> Grouping Data</a><ul>
<li class="chapter" data-level="5.9.1" data-path="data-manipulation-2.html"><a href="data-manipulation-2.html#ungrouping-data"><i class="fa fa-check"></i><b>5.9.1</b> Ungrouping Data</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="data-manipulation-2.html"><a href="data-manipulation-2.html#chaining-many-functions"><i class="fa fa-check"></i><b>5.10</b> Chaining Many Functions</a></li>
<li class="chapter" data-level="5.11" data-path="data-manipulation-2.html"><a href="data-manipulation-2.html#saving-data"><i class="fa fa-check"></i><b>5.11</b> Saving Data</a><ul>
<li class="chapter" data-level="5.11.1" data-path="data-manipulation-2.html"><a href="data-manipulation-2.html#csv-files"><i class="fa fa-check"></i><b>5.11.1</b> CSV Files</a></li>
<li class="chapter" data-level="5.11.2" data-path="data-manipulation-2.html"><a href="data-manipulation-2.html#r-data-files"><i class="fa fa-check"></i><b>5.11.2</b> R Data Files</a></li>
</ul></li>
<li class="chapter" data-level="5.12" data-path="data-manipulation-2.html"><a href="data-manipulation-2.html#exercises-4"><i class="fa fa-check"></i><b>5.12</b> Exercises</a><ul>
<li class="chapter" data-level="5.12.1" data-path="data-manipulation-2.html"><a href="data-manipulation-2.html#question-1-4"><i class="fa fa-check"></i><b>5.12.1</b> Question 1</a></li>
<li class="chapter" data-level="5.12.2" data-path="data-manipulation-2.html"><a href="data-manipulation-2.html#question-2-4"><i class="fa fa-check"></i><b>5.12.2</b> Question 2</a></li>
<li class="chapter" data-level="5.12.3" data-path="data-manipulation-2.html"><a href="data-manipulation-2.html#question-3-4"><i class="fa fa-check"></i><b>5.12.3</b> Question 3</a></li>
<li class="chapter" data-level="5.12.4" data-path="data-manipulation-2.html"><a href="data-manipulation-2.html#question-4-4"><i class="fa fa-check"></i><b>5.12.4</b> Question 4</a></li>
<li class="chapter" data-level="5.12.5" data-path="data-manipulation-2.html"><a href="data-manipulation-2.html#question-5-4"><i class="fa fa-check"></i><b>5.12.5</b> Question 5</a></li>
<li class="chapter" data-level="5.12.6" data-path="data-manipulation-2.html"><a href="data-manipulation-2.html#question-6-4"><i class="fa fa-check"></i><b>5.12.6</b> Question 6</a></li>
<li class="chapter" data-level="5.12.7" data-path="data-manipulation-2.html"><a href="data-manipulation-2.html#question-7-4"><i class="fa fa-check"></i><b>5.12.7</b> Question 7</a></li>
<li class="chapter" data-level="5.12.8" data-path="data-manipulation-2.html"><a href="data-manipulation-2.html#question-8-4"><i class="fa fa-check"></i><b>5.12.8</b> Question 8</a></li>
<li class="chapter" data-level="5.12.9" data-path="data-manipulation-2.html"><a href="data-manipulation-2.html#question-9-4"><i class="fa fa-check"></i><b>5.12.9</b> Question 9</a></li>
<li class="chapter" data-level="5.12.10" data-path="data-manipulation-2.html"><a href="data-manipulation-2.html#question-10-3"><i class="fa fa-check"></i><b>5.12.10</b> Question 10</a></li>
<li class="chapter" data-level="5.12.11" data-path="data-manipulation-2.html"><a href="data-manipulation-2.html#question-11-1"><i class="fa fa-check"></i><b>5.12.11</b> Question 11</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="simple-statistical-tests.html"><a href="simple-statistical-tests.html"><i class="fa fa-check"></i><b>6</b> Simple Statistical Tests</a><ul>
<li class="chapter" data-level="6.1" data-path="simple-statistical-tests.html"><a href="simple-statistical-tests.html#getting-started-3"><i class="fa fa-check"></i><b>6.1</b> Getting Started</a></li>
<li class="chapter" data-level="6.2" data-path="simple-statistical-tests.html"><a href="simple-statistical-tests.html#correlation"><i class="fa fa-check"></i><b>6.2</b> Correlation</a><ul>
<li class="chapter" data-level="6.2.1" data-path="simple-statistical-tests.html"><a href="simple-statistical-tests.html#analysing-real-data"><i class="fa fa-check"></i><b>6.2.1</b> Analysing Real Data</a></li>
<li class="chapter" data-level="6.2.2" data-path="simple-statistical-tests.html"><a href="simple-statistical-tests.html#checking-assumptions"><i class="fa fa-check"></i><b>6.2.2</b> Checking Assumptions</a></li>
<li class="chapter" data-level="6.2.3" data-path="simple-statistical-tests.html"><a href="simple-statistical-tests.html#running-a-correlation"><i class="fa fa-check"></i><b>6.2.3</b> Running a Correlation</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="simple-statistical-tests.html"><a href="simple-statistical-tests.html#t-tests"><i class="fa fa-check"></i><b>6.3</b> <em>t</em>-tests</a><ul>
<li class="chapter" data-level="6.3.1" data-path="simple-statistical-tests.html"><a href="simple-statistical-tests.html#one-sample-t-tests"><i class="fa fa-check"></i><b>6.3.1</b> One-Sample <em>t</em>-tests</a></li>
<li class="chapter" data-level="6.3.2" data-path="simple-statistical-tests.html"><a href="simple-statistical-tests.html#independent-samples-t-tests"><i class="fa fa-check"></i><b>6.3.2</b> Independent-Samples <em>t</em>-tests</a></li>
<li class="chapter" data-level="6.3.3" data-path="simple-statistical-tests.html"><a href="simple-statistical-tests.html#paired-samples-t-tests"><i class="fa fa-check"></i><b>6.3.3</b> Paired-Samples <em>t</em>-tests</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="simple-statistical-tests.html"><a href="simple-statistical-tests.html#anova"><i class="fa fa-check"></i><b>6.4</b> ANOVA</a><ul>
<li class="chapter" data-level="6.4.1" data-path="simple-statistical-tests.html"><a href="simple-statistical-tests.html#one-way-anova"><i class="fa fa-check"></i><b>6.4.1</b> One-Way ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="simple-statistical-tests.html"><a href="simple-statistical-tests.html#linear-regression"><i class="fa fa-check"></i><b>6.5</b> Linear Regression</a><ul>
<li class="chapter" data-level="6.5.1" data-path="simple-statistical-tests.html"><a href="simple-statistical-tests.html#general-linear-model"><i class="fa fa-check"></i><b>6.5.1</b> General Linear Model</a></li>
<li class="chapter" data-level="6.5.2" data-path="simple-statistical-tests.html"><a href="simple-statistical-tests.html#generalised-linear-model"><i class="fa fa-check"></i><b>6.5.2</b> Generalised Linear Model</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="simple-statistical-tests.html"><a href="simple-statistical-tests.html#exercises-5"><i class="fa fa-check"></i><b>6.6</b> Exercises</a><ul>
<li class="chapter" data-level="6.6.1" data-path="simple-statistical-tests.html"><a href="simple-statistical-tests.html#question-1-5"><i class="fa fa-check"></i><b>6.6.1</b> Question 1</a></li>
<li class="chapter" data-level="6.6.2" data-path="simple-statistical-tests.html"><a href="simple-statistical-tests.html#question-2-5"><i class="fa fa-check"></i><b>6.6.2</b> Question 2</a></li>
<li class="chapter" data-level="6.6.3" data-path="simple-statistical-tests.html"><a href="simple-statistical-tests.html#question-3-5"><i class="fa fa-check"></i><b>6.6.3</b> Question 3</a></li>
<li class="chapter" data-level="6.6.4" data-path="simple-statistical-tests.html"><a href="simple-statistical-tests.html#question-4-5"><i class="fa fa-check"></i><b>6.6.4</b> Question 4</a></li>
<li class="chapter" data-level="6.6.5" data-path="simple-statistical-tests.html"><a href="simple-statistical-tests.html#question-5-5"><i class="fa fa-check"></i><b>6.6.5</b> Question 5</a></li>
<li class="chapter" data-level="6.6.6" data-path="simple-statistical-tests.html"><a href="simple-statistical-tests.html#question-6-5"><i class="fa fa-check"></i><b>6.6.6</b> Question 6</a></li>
<li class="chapter" data-level="6.6.7" data-path="simple-statistical-tests.html"><a href="simple-statistical-tests.html#question-7-5"><i class="fa fa-check"></i><b>6.6.7</b> Question 7</a></li>
<li class="chapter" data-level="6.6.8" data-path="simple-statistical-tests.html"><a href="simple-statistical-tests.html#question-8-5"><i class="fa fa-check"></i><b>6.6.8</b> Question 8</a></li>
<li class="chapter" data-level="6.6.9" data-path="simple-statistical-tests.html"><a href="simple-statistical-tests.html#question-9-5"><i class="fa fa-check"></i><b>6.6.9</b> Question 9</a></li>
<li class="chapter" data-level="6.6.10" data-path="simple-statistical-tests.html"><a href="simple-statistical-tests.html#question-10-4"><i class="fa fa-check"></i><b>6.6.10</b> Question 10</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="advanced-statistical-tests.html"><a href="advanced-statistical-tests.html"><i class="fa fa-check"></i><b>7</b> Advanced Statistical Tests</a><ul>
<li class="chapter" data-level="7.1" data-path="advanced-statistical-tests.html"><a href="advanced-statistical-tests.html#getting-started-4"><i class="fa fa-check"></i><b>7.1</b> Getting Started</a></li>
<li class="chapter" data-level="7.2" data-path="advanced-statistical-tests.html"><a href="advanced-statistical-tests.html#multilevel-analyses"><i class="fa fa-check"></i><b>7.2</b> Multilevel Analyses</a><ul>
<li class="chapter" data-level="7.2.1" data-path="advanced-statistical-tests.html"><a href="advanced-statistical-tests.html#preparation-of-data"><i class="fa fa-check"></i><b>7.2.1</b> Preparation of Data</a></li>
<li class="chapter" data-level="7.2.2" data-path="advanced-statistical-tests.html"><a href="advanced-statistical-tests.html#multilevel-regression"><i class="fa fa-check"></i><b>7.2.2</b> Multilevel Regression</a></li>
<li class="chapter" data-level="7.2.3" data-path="advanced-statistical-tests.html"><a href="advanced-statistical-tests.html#multilevel-anova"><i class="fa fa-check"></i><b>7.2.3</b> Multilevel ANOVA</a></li>
<li class="chapter" data-level="7.2.4" data-path="advanced-statistical-tests.html"><a href="advanced-statistical-tests.html#multiple-contrasts"><i class="fa fa-check"></i><b>7.2.4</b> Multiple Contrasts</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="advanced-statistical-tests.html"><a href="advanced-statistical-tests.html#multifactorial-analyses"><i class="fa fa-check"></i><b>7.3</b> Multifactorial Analyses</a><ul>
<li class="chapter" data-level="7.3.1" data-path="advanced-statistical-tests.html"><a href="advanced-statistical-tests.html#multifactorial-anova"><i class="fa fa-check"></i><b>7.3.1</b> Multifactorial ANOVA</a></li>
<li class="chapter" data-level="7.3.2" data-path="advanced-statistical-tests.html"><a href="advanced-statistical-tests.html#multiple-regression"><i class="fa fa-check"></i><b>7.3.2</b> Multiple Regression</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="advanced-statistical-tests.html"><a href="advanced-statistical-tests.html#mixed-analyses"><i class="fa fa-check"></i><b>7.4</b> Mixed Analyses</a><ul>
<li class="chapter" data-level="7.4.1" data-path="advanced-statistical-tests.html"><a href="advanced-statistical-tests.html#mixed-linear-models"><i class="fa fa-check"></i><b>7.4.1</b> Mixed Linear Models</a></li>
<li class="chapter" data-level="7.4.2" data-path="advanced-statistical-tests.html"><a href="advanced-statistical-tests.html#mixed-anova"><i class="fa fa-check"></i><b>7.4.2</b> Mixed ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="advanced-statistical-tests.html"><a href="advanced-statistical-tests.html#a-note-on-sum-of-squares"><i class="fa fa-check"></i><b>7.5</b> A Note on Sum of Squares</a></li>
<li class="chapter" data-level="7.6" data-path="advanced-statistical-tests.html"><a href="advanced-statistical-tests.html#exercises-6"><i class="fa fa-check"></i><b>7.6</b> Exercises</a><ul>
<li class="chapter" data-level="7.6.1" data-path="advanced-statistical-tests.html"><a href="advanced-statistical-tests.html#question-1-6"><i class="fa fa-check"></i><b>7.6.1</b> Question 1</a></li>
<li class="chapter" data-level="7.6.2" data-path="advanced-statistical-tests.html"><a href="advanced-statistical-tests.html#question-2-6"><i class="fa fa-check"></i><b>7.6.2</b> Question 2</a></li>
<li class="chapter" data-level="7.6.3" data-path="advanced-statistical-tests.html"><a href="advanced-statistical-tests.html#question-3-6"><i class="fa fa-check"></i><b>7.6.3</b> Question 3</a></li>
<li class="chapter" data-level="7.6.4" data-path="advanced-statistical-tests.html"><a href="advanced-statistical-tests.html#question-4-6"><i class="fa fa-check"></i><b>7.6.4</b> Question 4</a></li>
<li class="chapter" data-level="7.6.5" data-path="advanced-statistical-tests.html"><a href="advanced-statistical-tests.html#question-5-6"><i class="fa fa-check"></i><b>7.6.5</b> Question 5</a></li>
<li class="chapter" data-level="7.6.6" data-path="advanced-statistical-tests.html"><a href="advanced-statistical-tests.html#question-6-6"><i class="fa fa-check"></i><b>7.6.6</b> Question 6</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="simulation-and-calculating-power.html"><a href="simulation-and-calculating-power.html"><i class="fa fa-check"></i><b>8</b> Simulation and Calculating Power</a><ul>
<li class="chapter" data-level="8.1" data-path="simulation-and-calculating-power.html"><a href="simulation-and-calculating-power.html#getting-started-5"><i class="fa fa-check"></i><b>8.1</b> Getting Started</a></li>
<li class="chapter" data-level="8.2" data-path="simulation-and-calculating-power.html"><a href="simulation-and-calculating-power.html#simulating-data"><i class="fa fa-check"></i><b>8.2</b> Simulating Data</a><ul>
<li class="chapter" data-level="8.2.1" data-path="simulation-and-calculating-power.html"><a href="simulation-and-calculating-power.html#the-uniform-distribution"><i class="fa fa-check"></i><b>8.2.1</b> The Uniform Distribution</a></li>
<li class="chapter" data-level="8.2.2" data-path="simulation-and-calculating-power.html"><a href="simulation-and-calculating-power.html#the-normal-distribution"><i class="fa fa-check"></i><b>8.2.2</b> The Normal Distribution</a></li>
<li class="chapter" data-level="8.2.3" data-path="simulation-and-calculating-power.html"><a href="simulation-and-calculating-power.html#the-binomial-distribution"><i class="fa fa-check"></i><b>8.2.3</b> The Binomial Distribution</a></li>
<li class="chapter" data-level="8.2.4" data-path="simulation-and-calculating-power.html"><a href="simulation-and-calculating-power.html#flexible-sampling"><i class="fa fa-check"></i><b>8.2.4</b> Flexible Sampling</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="simulation-and-calculating-power.html"><a href="simulation-and-calculating-power.html#sampling-for-inference"><i class="fa fa-check"></i><b>8.3</b> Sampling for Inference</a><ul>
<li class="chapter" data-level="8.3.1" data-path="simulation-and-calculating-power.html"><a href="simulation-and-calculating-power.html#understanding-p-values-and-type-i-errors"><i class="fa fa-check"></i><b>8.3.1</b> Understanding p-values and Type-I Errors</a></li>
<li class="chapter" data-level="8.3.2" data-path="simulation-and-calculating-power.html"><a href="simulation-and-calculating-power.html#understanding-power-and-type-ii-errors"><i class="fa fa-check"></i><b>8.3.2</b> Understanding Power and Type-II Errors</a></li>
<li class="chapter" data-level="8.3.3" data-path="simulation-and-calculating-power.html"><a href="simulation-and-calculating-power.html#flexible-power-analyses-with-simulation"><i class="fa fa-check"></i><b>8.3.3</b> Flexible Power Analyses with Simulation</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="simulation-and-calculating-power.html"><a href="simulation-and-calculating-power.html#performing-power-analyses-from-packages"><i class="fa fa-check"></i><b>8.4</b> Performing Power Analyses from Packages</a></li>
<li class="chapter" data-level="8.5" data-path="simulation-and-calculating-power.html"><a href="simulation-and-calculating-power.html#exercises-7"><i class="fa fa-check"></i><b>8.5</b> Exercises</a><ul>
<li class="chapter" data-level="8.5.1" data-path="simulation-and-calculating-power.html"><a href="simulation-and-calculating-power.html#introduction-and-setup-1"><i class="fa fa-check"></i><b>8.5.1</b> Introduction and Setup</a></li>
<li class="chapter" data-level="8.5.2" data-path="simulation-and-calculating-power.html"><a href="simulation-and-calculating-power.html#question-1-7"><i class="fa fa-check"></i><b>8.5.2</b> Question 1</a></li>
<li class="chapter" data-level="8.5.3" data-path="simulation-and-calculating-power.html"><a href="simulation-and-calculating-power.html#question-2-7"><i class="fa fa-check"></i><b>8.5.3</b> Question 2</a></li>
<li class="chapter" data-level="8.5.4" data-path="simulation-and-calculating-power.html"><a href="simulation-and-calculating-power.html#question-3-7"><i class="fa fa-check"></i><b>8.5.4</b> Question 3</a></li>
<li class="chapter" data-level="8.5.5" data-path="simulation-and-calculating-power.html"><a href="simulation-and-calculating-power.html#question-4-7"><i class="fa fa-check"></i><b>8.5.5</b> Question 4</a></li>
<li class="chapter" data-level="8.5.6" data-path="simulation-and-calculating-power.html"><a href="simulation-and-calculating-power.html#question-5-7"><i class="fa fa-check"></i><b>8.5.6</b> Question 5</a></li>
<li class="chapter" data-level="8.5.7" data-path="simulation-and-calculating-power.html"><a href="simulation-and-calculating-power.html#question-6-7"><i class="fa fa-check"></i><b>8.5.7</b> Question 6</a></li>
<li class="chapter" data-level="8.5.8" data-path="simulation-and-calculating-power.html"><a href="simulation-and-calculating-power.html#question-7-6"><i class="fa fa-check"></i><b>8.5.8</b> Question 7</a></li>
<li class="chapter" data-level="8.5.9" data-path="simulation-and-calculating-power.html"><a href="simulation-and-calculating-power.html#question-8-6"><i class="fa fa-check"></i><b>8.5.9</b> Question 8</a></li>
<li class="chapter" data-level="8.5.10" data-path="simulation-and-calculating-power.html"><a href="simulation-and-calculating-power.html#question-9-6"><i class="fa fa-check"></i><b>8.5.10</b> Question 9</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="mixed-effects-models.html"><a href="mixed-effects-models.html"><i class="fa fa-check"></i><b>9</b> Mixed Effects Models</a><ul>
<li class="chapter" data-level="9.1" data-path="mixed-effects-models.html"><a href="mixed-effects-models.html#getting-started-6"><i class="fa fa-check"></i><b>9.1</b> Getting Started</a></li>
<li class="chapter" data-level="9.2" data-path="mixed-effects-models.html"><a href="mixed-effects-models.html#why-mixed-effects-models"><i class="fa fa-check"></i><b>9.2</b> Why Mixed Effects Models</a></li>
<li class="chapter" data-level="9.3" data-path="mixed-effects-models.html"><a href="mixed-effects-models.html#how-do-mixed-effects-models-work"><i class="fa fa-check"></i><b>9.3</b> How Do Mixed Effects Models Work?</a><ul>
<li class="chapter" data-level="9.3.1" data-path="mixed-effects-models.html"><a href="mixed-effects-models.html#fixed-and-random-effects"><i class="fa fa-check"></i><b>9.3.1</b> Fixed and Random Effects</a></li>
<li class="chapter" data-level="9.3.2" data-path="mixed-effects-models.html"><a href="mixed-effects-models.html#specifying-your-random-effects-structure"><i class="fa fa-check"></i><b>9.3.2</b> Specifying your Random Effects Structure</a></li>
<li class="chapter" data-level="9.3.3" data-path="mixed-effects-models.html"><a href="mixed-effects-models.html#partial-pooling-of-data"><i class="fa fa-check"></i><b>9.3.3</b> Partial-Pooling of Data</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="mixed-effects-models.html"><a href="mixed-effects-models.html#interpreting-mixed-effects-model-output"><i class="fa fa-check"></i><b>9.4</b> Interpreting Mixed Effects Model Output</a><ul>
<li class="chapter" data-level="9.4.1" data-path="mixed-effects-models.html"><a href="mixed-effects-models.html#calculating-p-values-for-parameter-estimates"><i class="fa fa-check"></i><b>9.4.1</b> Calculating p-values for Parameter Estimates</a></li>
<li class="chapter" data-level="9.4.2" data-path="mixed-effects-models.html"><a href="mixed-effects-models.html#model-selection"><i class="fa fa-check"></i><b>9.4.2</b> Model Selection</a></li>
<li class="chapter" data-level="9.4.3" data-path="mixed-effects-models.html"><a href="mixed-effects-models.html#failure-to-converge-what-should-i-do"><i class="fa fa-check"></i><b>9.4.3</b> Failure to Converge: What Should I Do?</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="mixed-effects-models.html"><a href="mixed-effects-models.html#test-assumptions"><i class="fa fa-check"></i><b>9.5</b> Test Assumptions</a></li>
<li class="chapter" data-level="9.6" data-path="mixed-effects-models.html"><a href="mixed-effects-models.html#generalised-mixed-effects-models"><i class="fa fa-check"></i><b>9.6</b> Generalised Mixed Effects Models</a></li>
<li class="chapter" data-level="9.7" data-path="mixed-effects-models.html"><a href="mixed-effects-models.html#a-note-on-power-effect-sizes-and-pairwise-comparisons"><i class="fa fa-check"></i><b>9.7</b> A Note on Power, Effect Sizes, and Pairwise Comparisons</a><ul>
<li class="chapter" data-level="9.7.1" data-path="mixed-effects-models.html"><a href="mixed-effects-models.html#power"><i class="fa fa-check"></i><b>9.7.1</b> Power</a></li>
<li class="chapter" data-level="9.7.2" data-path="mixed-effects-models.html"><a href="mixed-effects-models.html#effect-sizes"><i class="fa fa-check"></i><b>9.7.2</b> Effect Sizes</a></li>
<li class="chapter" data-level="9.7.3" data-path="mixed-effects-models.html"><a href="mixed-effects-models.html#pairwise-comparisons"><i class="fa fa-check"></i><b>9.7.3</b> Pairwise Comparisons</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="mixed-effects-models.html"><a href="mixed-effects-models.html#exercises-8"><i class="fa fa-check"></i><b>9.8</b> Exercises</a><ul>
<li class="chapter" data-level="9.8.1" data-path="mixed-effects-models.html"><a href="mixed-effects-models.html#question-1-8"><i class="fa fa-check"></i><b>9.8.1</b> Question 1</a></li>
<li class="chapter" data-level="9.8.2" data-path="mixed-effects-models.html"><a href="mixed-effects-models.html#question-2-8"><i class="fa fa-check"></i><b>9.8.2</b> Question 2</a></li>
<li class="chapter" data-level="9.8.3" data-path="mixed-effects-models.html"><a href="mixed-effects-models.html#question-3-8"><i class="fa fa-check"></i><b>9.8.3</b> Question 3</a></li>
<li class="chapter" data-level="9.8.4" data-path="mixed-effects-models.html"><a href="mixed-effects-models.html#question-4-8"><i class="fa fa-check"></i><b>9.8.4</b> Question 4</a></li>
<li class="chapter" data-level="9.8.5" data-path="mixed-effects-models.html"><a href="mixed-effects-models.html#question-5-8"><i class="fa fa-check"></i><b>9.8.5</b> Question 5</a></li>
<li class="chapter" data-level="9.8.6" data-path="mixed-effects-models.html"><a href="mixed-effects-models.html#question-6-8"><i class="fa fa-check"></i><b>9.8.6</b> Question 6</a></li>
<li class="chapter" data-level="9.8.7" data-path="mixed-effects-models.html"><a href="mixed-effects-models.html#question-7-7"><i class="fa fa-check"></i><b>9.8.7</b> Question 7</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="creating-reproducible-documents.html"><a href="creating-reproducible-documents.html"><i class="fa fa-check"></i><b>10</b> Creating Reproducible Documents</a><ul>
<li class="chapter" data-level="10.1" data-path="creating-reproducible-documents.html"><a href="creating-reproducible-documents.html#the-final-lesson"><i class="fa fa-check"></i><b>10.1</b> The Final Lesson</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">R for Psych</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="mixed-effects-models" class="section level1">
<h1><span class="header-section-number">Chapter 9</span> Mixed Effects Models</h1>
<p>In this session we’ll cover Linear/Hierarchical Mixed Effects Modelling. We’ll cover why you should use mixed effects modelling for your own analyses, how these models work, and how to define your models properly in R. Specifically, we’ll cover:</p>
<ul>
<li>Fixed and Random Effects</li>
<li>Random Intercepts and Slopes</li>
<li>Nested and Crossed Random Effects</li>
<li>Partial-Pooling of Data</li>
<li>Calculating <em>p</em>-values</li>
<li>Generalised Mixed Effects Models</li>
</ul>
<p>One nice introduction to mixed effects models is provided by Bodo Winter in two parts: <a href="http://www.bodowinter.com/tutorial/bw_LME_tutorial1.pdf">part one</a> and <a href="http://www.bodowinter.com/tutorial/bw_LME_tutorial2.pdf">part two</a> and you might want to check this out as further reading from this chapter.</p>
<div id="getting-started-6" class="section level2">
<h2><span class="header-section-number">9.1</span> Getting Started</h2>
<p>As always, we first need to load the <code>tidyverse</code> set of package. However, for this chapter we also need the <code>lme4</code> package. This package allows us to run mixed effects models in R using the <code>lmer</code> and <code>glmer</code> commands for linear mixed effects models and generalised linear mixed effects models respectively. These models are similar to linear models and generalised lienar models in that the first can take continuous, unbounded data, and the second takes bounded, discrete data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># load packages</span>
<span class="kw">library</span>(tidyverse)
<span class="kw">library</span>(lme4)</code></pre></div>
<p>Additionally, we’ll load the data set for this study. This is the inbuilt <code>sleepstudy</code> data set from <code>lme4</code>, but I’ve simulated 2 additional participants before removing a lot of their observations. This is to show you just how powerful mixed effects models are when we have missing data.</p>
</div>
<div id="why-mixed-effects-models" class="section level2">
<h2><span class="header-section-number">9.2</span> Why Mixed Effects Models</h2>
<p>In all of the previous analyses we’ve used so far, our models have assumed that we have independence between cases in our data. However, this assumption is often violated, which can cause some serious problems when it comes to interpreting our tests.</p>
<p>Let’s assume we’re interested in language learning in children from monolinguial and bilingual backgrounds. We may decide to test how well children learn an artificial language by going to several schools and testing children in the same year group from different classes.</p>
<p>If we fit a traditional linear model to our data, we implicitly make the assumption that learning should be the same regardless of the class or school the child attends. Yet we know this is unlikely to be true; schools reflect the demographics of an area and the school ethos, and individual teachers may be better or worse at teaching linguistics to children. This means that children within the same school are likely to be more similar to one another than to children from different schools. Moreover, children within the class are likely to be more similar to one another than to children in different classes. In this way, our data should be nested such that children should be defined as part of a specific class in a specific school, and our models should reflect this ordering.</p>
<p>With mixed effects models, we can directly model this dependency in our data. Moreover, mixed effects models make fewer strict assumptions to other tests (<span class="citation">A. Field, Miles, and Field (<a href="#ref-field2012discovering">2012</a>)</span>), such as:</p>
<ul>
<li><p>Homogeneity of regression slopes: Mixed effects models can directly model variability in slopes, so we needn’t make any assumption that slopes are similar across conditions (which is often untrue).</p></li>
<li><p>Assumption of independence: with independent-samples tests we often assume that data are unrelated to one-another. But again, this is often not the case; take learning over time. The same person provides multiple measurements at multiple time points. Mixed effects models can handle this well.</p></li>
<li><p>Complete data: Often, with traditional analyses you just have to throw away entire sources of data (e.g. participants) if one case (e.g. one trial) is missing. This isn’t the case with mixed effects models, where we can estimate missing data based on what we have available to us.</p></li>
</ul>
<p>For these reasons, by default you should probably pick mixed effects models to model your data.</p>
</div>
<div id="how-do-mixed-effects-models-work" class="section level2">
<h2><span class="header-section-number">9.3</span> How Do Mixed Effects Models Work?</h2>
<div id="fixed-and-random-effects" class="section level3">
<h3><span class="header-section-number">9.3.1</span> Fixed and Random Effects</h3>
<p>So far, we’ve only talked about our parameter estimates from a linear model in terms of factors and levels. However, you can also consider the factors in your study in terms of whether they are fixed or random effects. Typically, a <strong>fixed effect</strong> will contain all possible levels of a factor in the experiment, while a <strong>random effect</strong> will be a random sample of possible levels of a factor. In effect, we can only generalise our fixed effects results to the levels within an experiment, but we can generalise from our random effects to levels beyond those that took part in our study.</p>
<p>Returning to our classroom example, if we tested languge learning in one of two conditions in students from different schools and and classes, our fixed effect would be the condition for the study. Hence, the random effects would be everything else we’d like to generalise to outside of our study. We probably want to generalise our results to all classes and all schools, so our random effects would be students within classes within schools.</p>
<p>In traditional models, you can say that all of the effects of interest, or the factors in the model, are defined as fixed effects. However, with mixed effects models, we can have both fixed and random effects in our model (hence <strong>mixed effects</strong> models).</p>
<p>To fit a mixed effects model, we simply define our fixed effects like we normally do for a linear model. However, there are different ways that we can define our random effects. Your choice of definition incorporates your belief of how the random effects work. Let’s explore how the way in which we define our random effects influences our model fit.</p>
<div id="fixed-intercept-and-slope" class="section level4">
<h4><span class="header-section-number">9.3.1.1</span> Fixed Intercept and Slope</h4>
<p>To look at how mixed effects models work, we’ll use some toy data based on the <code>sleepstudy</code> data set from <strong>lme4</strong>. I made this quickly in another script, and you can load it using the code below.</p>
<p>This just makes three groups within our data, and we can look at this like conducting our study in three phases, with three different groups of people. As with the <code>sleepstudy</code> data set, this data set looks at the effect of days without sleep on reaction times.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sleep_groups &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;inputs/sleep_study_with_sim_groups.csv&quot;</span>)</code></pre></div>
<pre><code>## Parsed with column specification:
## cols(
##   Reaction = col_double(),
##   Days = col_integer(),
##   Subject = col_integer(),
##   Group = col_character()
## )</code></pre>
<p>If we were to fit this data to a traditional linear model, and we ignored the fact that we have a random effect in our study (Group), then our linear model coefficients might look like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lm</span>(Reaction ~<span class="st"> </span>Days, <span class="dt">data =</span> sleep_groups)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Reaction ~ Days, data = sleep_groups)
## 
## Coefficients:
## (Intercept)         Days  
##       371.7         15.4</code></pre>
<p>That is, we would get an intercept of approximately 351.5 and a slope of approximately 10.3 which is used to define the relationship for days on reaction times across all participants. This type of model looks against the raw data for the study looks like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="dt">data =</span> sleep_groups, <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x =</span> Days, <span class="dt">y =</span> Reaction)) +
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">na.rm =</span> T, <span class="kw">aes</span>(<span class="dt">col =</span> Group), <span class="dt">alpha =</span> <span class="fl">0.5</span>) +
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">na.rm =</span> T, <span class="dt">col =</span> <span class="st">&quot;black&quot;</span>, <span class="dt">se =</span> F) +
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">180</span>, <span class="dv">1020</span>)) +
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dv">1</span>:<span class="dv">10</span>) -<span class="st"> </span><span class="dv">1</span>) +
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;top&quot;</span>)</code></pre></div>
<p><img src="R_for_Psych_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>But, you can see from the colour of the points that we have 3 distinct groups of participants in our model. It’s clear that the three groups have different intercepts, and group 3 has a much steeper slope than the other two groups. Perhaps, then, we should model this difference across groups, even if it’s not the main factor of interest in our study.</p>
</div>
<div id="random-intercepts" class="section level4">
<h4><span class="header-section-number">9.3.1.2</span> Random Intercepts</h4>
<p>We define a mixed effects model in a similar way to a traditional linear model. Here, the only difference is we run the model using the <code>lmer()</code> function from <strong>lme4</strong>, rather than the <code>lm()</code> function from base R, and we specify our random effects as well.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># fit random intercepts model</span>
intercepts_model &lt;-<span class="st"> </span><span class="kw">lmer</span>(Reaction ~<span class="st"> </span>Days +<span class="st"> </span>(<span class="dv">1</span> |<span class="st"> </span>Group), <span class="dt">data =</span> sleep_groups)</code></pre></div>
<p>As with regular linear models, we define our response variable as the column name to the left of the <code>~</code> (read: tilde). We then define our fixed effects to the right of the <code>~</code>.</p>
<p>After this, we define our random effects in parentheses. Here, we have specified that we want <strong>random intercept (1)</strong> for each group; <code>(1 | Group)</code>. Notice that we have a <code>|</code> (read: pipe) between the 1 and group. This specifies what you want to calculate, by which random factor - here it is random intercepts (1) by the Group random factor.</p>
<p>Finally, as always we specify our data set, which should be in long format.</p>
<p>Let’s see how defining random intercepts affects the coefficients for the groups in our model. We can extract model coefficients using the <code>coef()</code> function. I specifically got the Group coefficients by asking for this using the dollar notation after the function call. To make this easier on the eyes I’ve renamed the columns, and created an identifier for the intercepts and slopes (i.e. the Group column).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># see group coefficients</span>
model_coefs &lt;-<span class="st"> </span><span class="kw">coef</span>(intercepts_model)$Group %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">rename</span>(<span class="dt">Intercept =</span> <span class="st">`</span><span class="dt">(Intercept)</span><span class="st">`</span>, <span class="dt">Slope =</span> Days) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">rownames_to_column</span>(<span class="st">&quot;Group&quot;</span>)

<span class="co"># see coefficients</span>
model_coefs</code></pre></div>
<pre><code>##     Group Intercept    Slope
## 1 group_1  229.3394 15.40385
## 2 group_2  329.0908 15.40385
## 3 group_3  556.6432 15.40385</code></pre>
<p>How would this model look against our raw data?</p>
<p>First, we’ll join these coefficients to our original data so we can plot the individual lines.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sleep_groups_rani &lt;-<span class="st"> </span><span class="kw">left_join</span>(sleep_groups, model_coefs, <span class="dt">by =</span> <span class="st">&quot;Group&quot;</span>)</code></pre></div>
<p>Then we’ll plot our original data with our new, random intercepts model. We’ll save this under the name <code>model_coef_plot</code> because we can use a simple ggplot function to update models without repeating code.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model_coef_plot &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="dt">data =</span> sleep_groups_rani, 
       <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x =</span> Days, 
                     <span class="dt">y =</span> Reaction, 
                     <span class="dt">colour =</span> Group)
       ) +
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">na.rm =</span> T, <span class="dt">alpha =</span> <span class="fl">0.5</span>) +
<span class="st">  </span><span class="kw">geom_abline</span>(<span class="kw">aes</span>(<span class="dt">intercept =</span> Intercept, 
                  <span class="dt">slope =</span> Slope,
                  <span class="dt">colour =</span> Group
                  ),
              <span class="dt">size =</span> <span class="fl">1.5</span>
              ) +
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">180</span>, <span class="dv">1020</span>)) +
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dv">1</span>:<span class="dv">10</span>) -<span class="st"> </span><span class="dv">1</span>) +
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;top&quot;</span>)

<span class="co"># see the plot</span>
model_coef_plot</code></pre></div>
<p><img src="R_for_Psych_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>Now you can see that we fit a model where the intercept (the y value at x = 0) differs across the 3 groups, but the slope of the lines is the same.</p>
<p>You might pick a random effects structure with random intercepts for data like this if you expect the three groups to differ from one another at the start of testing, but the effect of days on reaction times is the same across groups.</p>
</div>
<div id="random-slopes" class="section level4">
<h4><span class="header-section-number">9.3.1.3</span> Random Slopes</h4>
<p>Alternatively, we can specify a random effects structure with random slopes but fixed intercepts. We might pick this form if we expect all groups to start off at around the same score, but that the effects of days on reaction times differs across groups.</p>
<p>To specify this random effects structure, we change the 1 to a 0 in our random effects structure (specifying no or 0 random intercepts) and we put Days to the left of the <code>|</code>, meaning that we want to calculate random slopes for the effect of Days for each Group.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># fit random intercepts model</span>
model &lt;-<span class="st"> </span><span class="kw">lmer</span>(Reaction ~<span class="st"> </span>Days +<span class="st"> </span>(<span class="dv">0</span> +<span class="st"> </span>Days |<span class="st"> </span>Group), <span class="dt">data =</span> sleep_groups)

<span class="co"># see group coefficients</span>
model_coefs &lt;-<span class="st"> </span><span class="kw">coef</span>(model)$Group %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">rename</span>(<span class="dt">Intercept =</span> <span class="st">`</span><span class="dt">(Intercept)</span><span class="st">`</span>, <span class="dt">Slope =</span> Days) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">rownames_to_column</span>(<span class="st">&quot;Group&quot;</span>)

<span class="co"># see coefficients</span>
model_coefs</code></pre></div>
<pre><code>##     Group Intercept     Slope
## 1 group_1  371.6912 -8.479087
## 2 group_2  371.6912  7.249332
## 3 group_3  371.6912 47.441298</code></pre>
<p>Next, we’ll join these coefficients to our original data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sleep_groups_rans &lt;-<span class="st"> </span><span class="kw">left_join</span>(sleep_groups, model_coefs, <span class="dt">by =</span> <span class="st">&quot;Group&quot;</span>)</code></pre></div>
<p>Then we’ll plot our original data with our new, random intercepts model. Here, we’ll use a new, cheat function from ggplot, <code>%+%</code> (read: add components). This takes a fitted plot from ggplot, and replaces the data from that plot with whatever comes to the right of the function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model_coef_plot %+%<span class="st"> </span>sleep_groups_rans</code></pre></div>
<p><img src="R_for_Psych_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>In the above plot, we can now see that our data has the same intercept across groups, but different slopes. It seems that the effect of days without sleep is greatest for group 3.</p>
</div>
<div id="random-intercepts-and-slopes" class="section level4">
<h4><span class="header-section-number">9.3.1.4</span> Random Intercepts and Slopes</h4>
<p>Finally, we can specify that we want random intercepts and slopes for the group. Here, we just change the 0 back to a 1 in the random effects call.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># fit random intercepts model</span>
model &lt;-<span class="st"> </span><span class="kw">lmer</span>(Reaction ~<span class="st"> </span>Days +<span class="st"> </span>(<span class="dv">1</span> +<span class="st"> </span>Days |<span class="st"> </span>Group), <span class="dt">data =</span> sleep_groups)</code></pre></div>
<p>Let’s see how these coefficients look.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># see group coefficients</span>
model_coefs &lt;-<span class="st"> </span><span class="kw">coef</span>(model)$Group %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">rename</span>(<span class="dt">Intercept =</span> <span class="st">`</span><span class="dt">(Intercept)</span><span class="st">`</span>, <span class="dt">Slope =</span> Days) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">rownames_to_column</span>(<span class="st">&quot;Group&quot;</span>)

<span class="co"># see coefficients</span>
model_coefs</code></pre></div>
<pre><code>##     Group Intercept     Slope
## 1 group_1  256.4992  9.456212
## 2 group_2  344.2956 11.894381
## 3 group_3  514.2786 24.860950</code></pre>
<p>Next, we’ll join these coefficients to our original data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sleep_groups_ranis &lt;-<span class="st"> </span><span class="kw">left_join</span>(sleep_groups, model_coefs, <span class="dt">by =</span> <span class="st">&quot;Group&quot;</span>)</code></pre></div>
<p>Then we’ll plot our original data with our new, random intercepts and random slopes model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model_coef_plot %+%<span class="st"> </span>sleep_groups_ranis</code></pre></div>
<p><img src="R_for_Psych_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>As you can see, our model now fits random intercepts and slopes for each group of our participants.</p>
</div>
</div>
<div id="specifying-your-random-effects-structure" class="section level3">
<h3><span class="header-section-number">9.3.2</span> Specifying your Random Effects Structure</h3>
<p>There’s some debate on how to specify your random effects, but one good rule of thumb is to <a href="https://www.sciencedirect.com/science/article/pii/S0749596X12001180">keep it maximal</a>. From several simulations, Dale Barr and colleagues have found that models that use the maximal random effects structure justified by the design of the study tend to have a good balance between power and type-I error rates (specifically keeping error below the nominal <span class="math inline">\(\alpha\)</span>).</p>
<p>What does a maximal random effect structure look like? Typically, it will fit random intercepts, slopes, and the correlation between the two for any main effects and interactions in the model.</p>
<p><a href="https://www.sciencedirect.com/science/article/pii/S0749596X17300013">Not all researchers agree that this is always the best choice</a>. Indeed, some argue that you should evaluate the goodness of fit for models with and without more complex terms in the model (such as random slopes and interactions) in order to get the best trade off between power and type-I error rates, especially at smaller sample sizes, and that maximal models inflate type-II error rates. The choice is up to you, but be informed about the choice you make.</p>
<div id="crossed-and-nested-random-effects" class="section level4">
<h4><span class="header-section-number">9.3.2.1</span> Crossed and Nested Random Effects</h4>
<p>To understand how to define your random effects, we’ll look at some more simulated data. For illustration purposes, we won’t fit these models (we’d really need more data for that), but just pay attention to the structure of the models.</p>
<div id="crossed-random-effects" class="section level5">
<h5><span class="header-section-number">9.3.2.1.1</span> Crossed Random Effects</h5>
<p>The random effects structure that you take should reflect the reality of the data. If you have a design where observations can be assigned to more than one random effect simultaneously, then these random effects are said to be crossed.</p>
<p>This is often the case when you have a repeated measures design where participants provide multiple observations through responding to several items. In this instance, each observation comes from an individual subject on an individual item at the same time, making each observation a unique combination of these random factors. Hence, the random effects of subjects and items are said to be crossed.</p>
<p>For this example, our data could look like the following:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">crossed_data &lt;-<span class="st"> </span><span class="kw">tibble</span>(
  <span class="dt">Subject =</span> <span class="kw">rep</span>(<span class="dv">1</span>:<span class="dv">2</span>, <span class="dv">5</span>),
  <span class="dt">Item =</span> <span class="kw">rep</span>(<span class="dv">1</span>:<span class="dv">5</span>, <span class="dt">each =</span> <span class="dv">2</span>),
  <span class="dt">Condition =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>), <span class="dv">2</span>), <span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;B&quot;</span>, <span class="st">&quot;A&quot;</span>), <span class="dv">3</span>)),
  <span class="dt">Response =</span> <span class="kw">rnorm</span>(<span class="dt">n =</span> <span class="dv">10</span>, <span class="dt">mean =</span> <span class="dv">100</span>, <span class="dt">sd =</span> <span class="dv">10</span>)
)
crossed_data</code></pre></div>
<pre><code>## # A tibble: 10 x 4
##    Subject  Item Condition Response
##      &lt;int&gt; &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt;
##  1       1     1 A             92.8
##  2       2     1 B             85.0
##  3       1     2 A            108  
##  4       2     2 B            109  
##  5       1     3 B            100  
##  6       2     3 A            106  
##  7       1     4 B             92.8
##  8       2     4 A            111  
##  9       1     5 B            118  
## 10       2     5 A            105</code></pre>
<p>Here, both participants take part in both conditions (A or B), hence this is a within-subjects design (but note that this dummy set is not balanced; real designs should be where possible). The condition (A or B) is therefore within individual subjects and individual items, but items are not only associated with one subject. Hence, our random effects are crossed, and should look like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lmer</span>(Response ~<span class="st"> </span>Condition +<span class="st"> </span>(<span class="dv">1</span> |<span class="st"> </span>Subject) +<span class="st"> </span>(<span class="dv">1</span> |<span class="st"> </span>Item), <span class="dt">data =</span> crossed_data)</code></pre></div>
</div>
<div id="nested-random-effects" class="section level5">
<h5><span class="header-section-number">9.3.2.1.2</span> Nested Random Effects</h5>
<p>Sometimes we get cases when our data are not crossed. For example, if you’re testing participants from separate classes in separate schools, then your data can be said to be nested. The data are nested because observations come from students, which are a part of a specific class, and a specific school. In this instance, you should construct your data to reflect this nesting, ending up with something like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">nested_data &lt;-<span class="st"> </span><span class="kw">tibble</span>(
  <span class="dt">Student =</span> <span class="kw">seq</span>(<span class="dv">1</span>:<span class="dv">10</span>),
  <span class="dt">Class =</span> <span class="kw">rep</span>(<span class="kw">seq</span>(<span class="dv">1</span>:<span class="dv">5</span>), <span class="dv">2</span>),
  <span class="dt">School =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="dv">1</span>, <span class="dv">5</span>), <span class="kw">rep</span>(<span class="dv">2</span>, <span class="dv">5</span>)),
  <span class="dt">Intervention =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;yes&quot;</span>, <span class="st">&quot;no&quot;</span>), <span class="dv">5</span>),
  <span class="dt">Outcome =</span> <span class="kw">rnorm</span>(<span class="dt">n =</span> <span class="dv">10</span>, <span class="dt">mean =</span> <span class="dv">200</span>, <span class="dt">sd =</span> <span class="dv">20</span>)
)

nested_data</code></pre></div>
<pre><code>## # A tibble: 10 x 5
##    Student Class School Intervention Outcome
##      &lt;int&gt; &lt;int&gt;  &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;
##  1       1     1   1.00 yes              195
##  2       2     2   1.00 no               191
##  3       3     3   1.00 yes              184
##  4       4     4   1.00 no               169
##  5       5     5   1.00 yes              249
##  6       6     1   2.00 no               232
##  7       7     2   2.00 yes              224
##  8       8     3   2.00 no               199
##  9       9     4   2.00 yes              170
## 10      10     5   2.00 no               171</code></pre>
<p>As you can see, your data are structured so that you have individuals with an identifier (column) for the class that they’re in and for the school that they’re in. We then have a column indicating whether or not students received an intervention, and their outcome on some test.</p>
<p>As a result, class 1 in school 1 is different to class 1 in school 2. How do you tell R to treat the data such that classes are nested within schools? Or to account for the school and class effects for each participant? We use a formula like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lmer</span>(Outcome ~<span class="st"> </span>Intervention +<span class="st"> </span>(<span class="dv">1</span> |<span class="st"> </span>School/Class/Student), <span class="dt">data =</span> nested_data)</code></pre></div>
<p>Here, our random effects structure defines random intercepts for students, adjusting for similarities for students within the same class and school.</p>
<p>It’s sometimes hard to figure out if you have nested or crossed (i.e. not nested) data, and you can help your thinking (and Rs functioning) by simply using unique class identifiers for your school and class combinations. We can make this by simply pasting the identifiers for the School and Class together.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">nested_data$Class_ID &lt;-<span class="st"> </span><span class="kw">paste</span>(nested_data$School, nested_data$Class, <span class="dt">sep =</span> <span class="st">&quot;_&quot;</span>)
nested_data</code></pre></div>
<pre><code>## # A tibble: 10 x 6
##    Student Class School Intervention Outcome Class_ID
##      &lt;int&gt; &lt;int&gt;  &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;   
##  1       1     1   1.00 yes              195 1_1     
##  2       2     2   1.00 no               191 1_2     
##  3       3     3   1.00 yes              184 1_3     
##  4       4     4   1.00 no               169 1_4     
##  5       5     5   1.00 yes              249 1_5     
##  6       6     1   2.00 no               232 2_1     
##  7       7     2   2.00 yes              224 2_2     
##  8       8     3   2.00 no               199 2_3     
##  9       9     4   2.00 yes              170 2_4     
## 10      10     5   2.00 no               171 2_5</code></pre>
<p>Now your results will be exactly the same if you use either of these two formulas:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lmer</span>(Outcome ~<span class="st"> </span>Intervention +<span class="st"> </span>(<span class="dv">1</span> |<span class="st"> </span>School/Class_ID), <span class="dt">data =</span> nested_data)
<span class="kw">lmer</span>(Outcome ~<span class="st"> </span>Intervention +<span class="st"> </span>(<span class="dv">1</span> |<span class="st"> </span>School) +<span class="st"> </span>(<span class="dv">1</span> |<span class="st"> </span>Class_ID), <span class="dt">data =</span> nested_data)</code></pre></div>
<p>If you don’t have unique identifiers, using this second structure will give you incorrect results as R will think that every class was in every school, which is not the case.</p>
<p>These random effects structures take the simplest form where we have random intercepts only. In most cases, it’s best to fit a more complex model depending upon the data you have.</p>
</div>
</div>
<div id="exploring-different-random-effects-structres" class="section level4">
<h4><span class="header-section-number">9.3.2.2</span> Exploring Different Random Effects Structres</h4>
<p>Let’s say we have a within subjects design, where participants see half of the items in our study in one condition, and half in another condition. Let’s take the <code>crossed_data</code> example from before.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">crossed_data</code></pre></div>
<pre><code>## # A tibble: 10 x 4
##    Subject  Item Condition Response
##      &lt;int&gt; &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt;
##  1       1     1 A             92.8
##  2       2     1 B             85.0
##  3       1     2 A            108  
##  4       2     2 B            109  
##  5       1     3 B            100  
##  6       2     3 A            106  
##  7       1     4 B             92.8
##  8       2     4 A            111  
##  9       1     5 B            118  
## 10       2     5 A            105</code></pre>
<p>Here, we could fit random intercepts and slopes for subjects and items by adding condition (our slope term, or change in response for changes in 1 unit of condition) to the left of each term (along with the random intercept).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lmer</span>(Outcome ~<span class="st"> </span>Condition +<span class="st"> </span>(<span class="dv">1</span> +<span class="st"> </span>Condition |<span class="st"> </span>Subject) +<span class="st"> </span>(<span class="dv">1</span> +<span class="st"> </span>Condition |<span class="st"> </span>Item), <span class="dt">data =</span> data)</code></pre></div>
<p>What if participants take part in several blocks of this study? We might expect that their performance will improve from block to block. Here, we’d just have to add a fixed effect of study block and random effects on any factors that are affected by the blocking. If you repeat your items across blocks with the same subjects, you’d have random effects of block on subjects and items (along with condition). If you have new items in each block, you’d only have random slopes of block for subjects. These random effects structures look like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># same items within each block</span>
<span class="kw">lmer</span>(
  Outcome ~<span class="st"> </span>Condition +<span class="st"> </span>Block +<span class="st"> </span>
<span class="st">    </span>(<span class="dv">1</span> +<span class="st"> </span>Condition +<span class="st"> </span>Block |<span class="st"> </span>Subject) +<span class="st"> </span>
<span class="st">    </span>(<span class="dv">1</span> +<span class="st"> </span>Condition +<span class="st"> </span>Block |<span class="st"> </span>Item), 
  <span class="dt">data =</span> data
  )

<span class="co"># new items within each block</span>
<span class="kw">lmer</span>(
  Outcome ~<span class="st"> </span>Condition +<span class="st"> </span>Block +<span class="st"> </span>
<span class="st">    </span>(<span class="dv">1</span> +<span class="st"> </span>Condition +<span class="st"> </span>Block |<span class="st"> </span>Subject) +<span class="st"> </span>
<span class="st">    </span>(<span class="dv">1</span> +<span class="st"> </span>Condition |<span class="st"> </span>Item), 
  <span class="dt">data =</span> data
  )</code></pre></div>
<p>As you might have guessed, for any between subjects factors, we cannot have a random slope of condition for that factor for each subject as subjects only see one condition. Here, our model might look like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lmer</span>(
  Outcome ~<span class="st"> </span>Condition +<span class="st"> </span>
<span class="st">    </span>(<span class="dv">1</span> |<span class="st"> </span>Subject) +<span class="st"> </span>
<span class="st">    </span>(<span class="dv">1</span> +<span class="st"> </span>Condition |<span class="st"> </span>Item), 
  <span class="dt">data =</span> data
  )</code></pre></div>
<p>Where we can have random slopes for condition by item (as all items presumably see all conditions), but only random intercepts for subjects as they only see one condition.</p>
<p>Finally, as with all linear models, if we want an interaction between factors, we simply use an asterisk between factors to define our interactions, or a colon if we only want the interaction term and not main effects. This could take the form below if we want random intercepts and slopes for both factors on subjects and items, with main effects and interactions on our fixed factors.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lmer</span>(
  Outcome ~<span class="st"> </span>factor_A *<span class="st"> </span>factor_B +<span class="st"> </span>
<span class="st">    </span>(<span class="dv">1</span> +<span class="st"> </span>factor_A *<span class="st"> </span>factor_B |<span class="st"> </span>Subject) +<span class="st"> </span>
<span class="st">    </span>(<span class="dv">1</span> +<span class="st"> </span>factor_A *<span class="st"> </span>factor_B |<span class="st"> </span>Item), 
  <span class="dt">data =</span> data
  )</code></pre></div>
<p>If you’d like to find out more about different structures, <a href="http://rpsychologist.com/r-guide-longitudinal-lme-lmer">Kristoffer Magnusson has a great guide</a> on this.</p>
</div>
</div>
<div id="partial-pooling-of-data" class="section level3">
<h3><span class="header-section-number">9.3.3</span> Partial-Pooling of Data</h3>
<p>Here, we’ll follow the first part of <a href="https://tjmahr.github.io/plotting-partial-pooling-in-mixed-effects-models/">TJ Mahr’s excellent write up</a> of partial-pooling, and why this is so important for mixed effects models. Additionally, we’ll see how partial-pooling allows mixed effects models to account for missing data.</p>
<p>We’ll use the same data set as in TJ’s article, the <code>sleepstudy</code> data set from the <code>lme4</code> package. I’ve already made some changes to this data set by convering it to a tibble and adding a few participants with missing data at the end by simulating new values based on the old participants, and simply deleting a few cells. Load the .csv file from the lesson materials folder to take a look at the data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sleep_study &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;inputs/sleep_study_with_sim.csv&quot;</span>)</code></pre></div>
<pre><code>## Parsed with column specification:
## cols(
##   Subject = col_integer(),
##   Days = col_integer(),
##   Reaction = col_double()
## )</code></pre>
<p>First off, we’ll fit a linear model to the data using complete pooling. This means that all of our data from each participant is put together to come up with one mean intercept and slope which is the same across all participants.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># fit model</span>
complete_pooling &lt;-<span class="st"> </span><span class="kw">lm</span>(Reaction ~<span class="st"> </span>Days, <span class="dt">data =</span> sleep_study)

<span class="co"># tidy up and print model coefficients</span>
complete_pooling_coefs &lt;-<span class="st"> </span><span class="kw">coef</span>(complete_pooling)
complete_pooling_coefs</code></pre></div>
<pre><code>## (Intercept)        Days 
##   252.09397    10.03451</code></pre>
<p>Next, we’ll fit this model against our mean scores (with standard errors), observing how an increase in the days without sleep decreases reaction time.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="dt">data =</span> sleep_study, <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x =</span> Days, <span class="dt">y =</span> Reaction)) +
<span class="st">  </span><span class="kw">geom_abline</span>(<span class="kw">aes</span>(<span class="dt">intercept =</span> complete_pooling_coefs[<span class="dv">1</span>], 
                  <span class="dt">slope =</span> complete_pooling_coefs[<span class="dv">2</span>]
                  ),
              <span class="dt">colour =</span> <span class="st">&quot;#F8766D&quot;</span>,
              <span class="dt">size =</span> <span class="fl">1.5</span>
              ) +
<span class="st">  </span><span class="kw">stat_summary</span>(<span class="dt">fun.data =</span> <span class="st">&quot;mean_se&quot;</span>, 
               <span class="dt">geom =</span> <span class="st">&quot;pointrange&quot;</span>,
               <span class="dt">na.rm =</span> T,
               <span class="dt">colour =</span> <span class="st">&quot;#F8766D&quot;</span>)</code></pre></div>
<p><img src="R_for_Psych_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<p>You can see that this line fits the mean scores pretty well. But how does the data look at the individual level? Again, we’ll save this plot as an object so we can update it later on. We’ll also join these coefficients with our data so that we can easily update our plot when we explore different pooling choices.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">complete &lt;-<span class="st"> </span><span class="kw">tibble</span>(
  <span class="dt">Subject =</span> <span class="kw">seq</span>(<span class="dv">1</span>:<span class="dv">21</span>),
  <span class="dt">Intercept =</span> complete_pooling_coefs[[<span class="dv">1</span>]],
  <span class="dt">Slope =</span> complete_pooling_coefs[[<span class="dv">2</span>]],
  <span class="dt">Model =</span> <span class="st">&quot;complete_pooling&quot;</span>
  )

model_coefs &lt;-<span class="st"> </span><span class="kw">left_join</span>(sleep_study, complete, <span class="dt">by =</span> <span class="st">&quot;Subject&quot;</span>)</code></pre></div>
<p>Let’s see how the data look with no pooling.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pooling_plot &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="dt">data =</span> model_coefs, 
       <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x =</span> Days, 
                     <span class="dt">y =</span> Reaction, 
                     <span class="dt">colour =</span> Model)
       ) +
<span class="st">  </span><span class="kw">geom_abline</span>(<span class="kw">aes</span>(<span class="dt">intercept =</span> Intercept, 
                  <span class="dt">slope =</span> Slope,
                  <span class="dt">colour =</span> Model),
              <span class="dt">size =</span> <span class="fl">1.5</span>
              ) +
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">na.rm =</span> T) +
<span class="st">  </span><span class="kw">facet_wrap</span>(~Subject)

<span class="co"># see the plot</span>
pooling_plot</code></pre></div>
<p><img src="R_for_Psych_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
<p>Wow, so it looks like the model fits participant 18 very well. But what about participants 1, 2, and 14? Maybe a different model would fit their data better. It doesn’t do a good job of explaining their responses, that’s for sure!</p>
<p>One alternative to this complete pooling method is the opposite: no pooling. Here, we instead fit an individual intercepts and slopes to each individual in the data. We can do this by using the <code>lmer()</code> function from <strong>lme4</strong>. Here, our formula takes the form where reaction times are a function of the days (of deprived sleep) within each participant.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># fit the model</span>
no_pooling &lt;-<span class="st"> </span><span class="kw">lmer</span>(Reaction ~<span class="st"> </span>Days |<span class="st"> </span>Subject, <span class="dt">data =</span> sleep_study)

<span class="co"># extract and view model coefficients</span>
no_pooling_coefs &lt;-<span class="st"> </span><span class="kw">coef</span>(no_pooling)$Subject %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">rename</span>(<span class="dt">Intercept =</span> <span class="st">`</span><span class="dt">(Intercept)</span><span class="st">`</span>, <span class="dt">Slope =</span> Days)

<span class="kw">head</span>(no_pooling_coefs)</code></pre></div>
<pre><code>##         Slope Intercept
## 1 20.60345661  249.4094
## 2 -0.02555511  219.9898
## 3  3.66034762  219.0878
## 4  4.24611744  281.1159
## 5  6.27933617  278.4035
## 6  9.56681539  263.1536</code></pre>
<p>We can see for the first 6 participants their intercepts and slopes (Days) all differ from one another. How does this look in our plot? First, we’ll add the two coefficients together for easy plotting.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">none &lt;-<span class="st"> </span><span class="kw">tibble</span>(
  <span class="dt">Subject =</span> <span class="kw">seq</span>(<span class="dv">1</span>:<span class="dv">21</span>),
  <span class="dt">Intercept =</span> no_pooling_coefs$Intercept,
  <span class="dt">Slope =</span> no_pooling_coefs$Slope,
  <span class="dt">Model =</span> <span class="st">&quot;no_pooling&quot;</span>
)
complete_none &lt;-<span class="st"> </span><span class="kw">bind_rows</span>(complete, none)
model_coefs &lt;-<span class="st"> </span><span class="kw">left_join</span>(sleep_study, complete_none, <span class="dt">by =</span> <span class="st">&quot;Subject&quot;</span>)</code></pre></div>
<p>Now we’ve got our data in the correct format for plotting, we can have a look at how our models fit our data. Which do you think best matches the individual? Is this model any good when we have a lot of missing data?</p>
<p>Take a look at participant 20. Do you think the no pooling model is any better than the complete pooling model? What about participant 2?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pooling_plot %+%<span class="st"> </span>model_coefs</code></pre></div>
<p><img src="R_for_Psych_files/figure-html/unnamed-chunk-32-1.png" width="672" /></p>
<p>Finally, we get to where <strong>lme4</strong> shines; partial pooling of results. Here, we’ll fit a mixed effects model where we have fixed effects of Days, which are assumed to be</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">partial_pooling &lt;-<span class="st"> </span><span class="kw">lmer</span>(Reaction ~<span class="st"> </span>Days +<span class="st"> </span>(Days |<span class="st"> </span>Subject), <span class="dt">data =</span> sleep_study)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># extract model coefficients</span>
partial_pooling_coefs &lt;-<span class="st"> </span><span class="kw">coef</span>(partial_pooling)$Subject

<span class="co"># make a tibble for partial pooling</span>
partial &lt;-<span class="st"> </span><span class="kw">tibble</span>(
  <span class="dt">Subject =</span> <span class="kw">seq</span>(<span class="dv">1</span>:<span class="dv">21</span>),
  <span class="dt">Intercept =</span> partial_pooling_coefs$<span class="st">`</span><span class="dt">(Intercept)</span><span class="st">`</span>,
  <span class="dt">Slope =</span> partial_pooling_coefs$Days,
  <span class="dt">Model =</span> <span class="st">&quot;partial_pooling&quot;</span>
)

<span class="co"># clean up and combine with other models</span>
partial &lt;-<span class="st"> </span>partial %&gt;%
<span class="st">  </span><span class="kw">left_join</span>(sleep_study, <span class="dt">by =</span> <span class="st">&quot;Subject&quot;</span>)

all_pools &lt;-<span class="st"> </span><span class="kw">bind_rows</span>(model_coefs, partial)</code></pre></div>
<p>Next, we can plot the different models against one another to see what happens.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pooling_plot %+%<span class="st"> </span>all_pools</code></pre></div>
<p><img src="R_for_Psych_files/figure-html/unnamed-chunk-35-1.png" width="672" /></p>
<p>As with TJ’s article, we’ll also zoom in to some of these participants too see what happens.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">subset_pools &lt;-<span class="st"> </span>all_pools %&gt;%<span class="st"> </span><span class="kw">filter</span>(Subject %in%<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">19</span>, <span class="dv">20</span>))
pooling_plot %+%<span class="st"> </span>subset_pools</code></pre></div>
<p><img src="R_for_Psych_files/figure-html/unnamed-chunk-36-1.png" width="672" /></p>
<p>Here, you can see that in the first two cases (1 and 2), the coefficients of the partial pooling model closely matches that of the no pooling model, showing that this model closely captures the individual differences within each participant.</p>
<p>Look at participant 20. You’ll notice that the partial and complete pooling lines are more similar to one another. That’s because while the partial pooling model fits individual intercepts and slopes for each participant, it is pulled towards the mean, i.e. the overall intercept and slope across all participants. That’s called shrinkage, where extreme values are pulled towards the average. This means that in cases where we have missing data, our model takes the best bet based on the grand mean, rather than trying to guess an individual intercept and slope based on that one person’s data.</p>
<p>If you’d like to learn more about how this works, I really recommend consulting the source of this work, the article by <a href="https://tjmahr.github.io/plotting-partial-pooling-in-mixed-effects-models/">TJ Mahr on partial pooling</a>.</p>
</div>
</div>
<div id="interpreting-mixed-effects-model-output" class="section level2">
<h2><span class="header-section-number">9.4</span> Interpreting Mixed Effects Model Output</h2>
<p>Now that we’ve seen how mixed effects models work, we’ll look at how to interpret the output of a mixed effects model. For this part, we’ll use the <code>lexdec</code> dataset from the <code>languageR</code> library. Load this by loading the library and running the code below.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(languageR)
lex_dec &lt;-<span class="st"> </span><span class="kw">as.tibble</span>(lexdec) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(Subject, Trial, Word, NativeLanguage, RT)</code></pre></div>
<p>In this data set, we have log transformed reaction times for English words rated by native and non-native speakers of English. Let’s assume that we are interested in the influence of native language on reaction times. First, we want to set the intercept to the mean across both groups. Since the data isn’t perfectly balanced, we should avoid the base <code>contrasts()</code> method from R, and instead centre our factors, so that one level is around -.5 and the other is .5. If your values aren’t exactly -.5/.5, then your data set is unbalanced, so your should use this method.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># centre the factor</span>
lex_dec$lang_c &lt;-<span class="st"> </span>(lex_dec$NativeLanguage ==<span class="st"> &quot;English&quot;</span>) -<span class="st"> </span><span class="kw">mean</span>(lex_dec$NativeLanguage ==<span class="st"> &quot;English&quot;</span>)

<span class="co"># see the result</span>
<span class="kw">head</span>(lex_dec)</code></pre></div>
<pre><code>## # A tibble: 6 x 6
##   Subject Trial Word       NativeLanguage    RT lang_c
##   &lt;fct&gt;   &lt;int&gt; &lt;fct&gt;      &lt;fct&gt;          &lt;dbl&gt;  &lt;dbl&gt;
## 1 A1         23 owl        English         6.34  0.429
## 2 A1         27 mole       English         6.31  0.429
## 3 A1         29 cherry     English         6.35  0.429
## 4 A1         30 pear       English         6.19  0.429
## 5 A1         32 dog        English         6.03  0.429
## 6 A1         33 blackberry English         6.18  0.429</code></pre>
<p>Then we’ll fit our model. We’ll start out with a relatively simple model where we have crossed random effects with random intercepts by subjects (Subject) and items (Word). We’ll then get a summary of our model to see what the <code>lmer</code> output looks like. We’ll fit all models with ML since we’re going to compare them to one another.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lexdec_mod &lt;-<span class="st"> </span><span class="kw">lmer</span>(RT ~<span class="st"> </span>lang_c +<span class="st"> </span>(<span class="dv">1</span> |<span class="st"> </span>Subject) +<span class="st"> </span>(<span class="dv">1</span> |<span class="st"> </span>Word), <span class="dt">data =</span> lex_dec, <span class="dt">REML =</span> F)
<span class="kw">summary</span>(lexdec_mod)</code></pre></div>
<pre><code>## Linear mixed model fit by maximum likelihood  [&#39;lmerMod&#39;]
## Formula: RT ~ lang_c + (1 | Subject) + (1 | Word)
##    Data: lex_dec
## 
##      AIC      BIC   logLik deviance df.resid 
##   -900.1   -873.0    455.1   -910.1     1654 
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -2.3600 -0.6142 -0.1196  0.4614  5.9658 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  Word     (Intercept) 0.005896 0.07678 
##  Subject  (Intercept) 0.016742 0.12939 
##  Residual             0.029842 0.17275 
## Number of obs: 1659, groups:  Word, 79; Subject, 21
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)  6.38509    0.02983   214.1
## lang_c      -0.15582    0.05770    -2.7
## 
## Correlation of Fixed Effects:
##        (Intr)
## lang_c 0.000</code></pre>
<p>There’s a few things to unpack here. First, our model was fitted with <strong>restricted maximum likelihood (REML)</strong> rather than <strong>maximum likelihood (ML)</strong>. These are just different ways to estimate the parameters of the model. Andy Field (<span class="citation">A. Field, Miles, and Field (<a href="#ref-field2012discovering">2012</a>)</span>) states that ML is typically better at estimating parameters for fixed regression parameters, and REML for random variances. The choice normally only makes a minor difference to the outcomes. However, we have to use ML if we want to compare model fits against one another.</p>
<p>Of most intereest to us are the random effects and fixed effects of the analysis. The random effects tells us how much variance in our data is captured by our random effects. Here, we can see that most of the variance is captured by the residuals (i.e. unexplained variance), but including random intercepts for subjects and items goes some way to explaining the differences in scores. Here, means are always assumed to be 0, so we only get the variance and standard deviation for these terms.</p>
<p>Next, we have the fixed effects. These roughly correspond to the parameter estimates from regular linear models that we’ve looked at. As we can see, we have a <em>t</em>-value of 2.57 for the effect of native language. The negative sign indicates that response times are slower for non-native speakers compared to the grand mean.</p>
<p>Finally, we get a correlation of our fixed effects, this is not the degree to which our fixed effects are related to one another, but is used for constructing confidence ellipses. We typically don’t use this in reporting our statistics.</p>
<div id="calculating-p-values-for-parameter-estimates" class="section level3">
<h3><span class="header-section-number">9.4.1</span> Calculating p-values for Parameter Estimates</h3>
<p>You may have noticed that <code>lme4</code> doesn’t provide you with <em>p</em>-values for your parameter estimates. That’s because there’s some discussion on whether or not we can accurately do so with mixed effects models, and also because the creators of lme4 would rather you use parameter estimates and their standard errors to infer the strenth of evidence for an effect.</p>
<p>We can easily calculate these using Kenward-Roger or Satterthwaite approximations, which are provided by the <strong>lmerTest</strong> and <strong>afex</strong> packages in R.</p>
<p>However, to avoid loading more packages, we can use the normal approximation to calculate <em>p</em>-values. The reasoning here is that with higher degrees of freedom, the t distribution matches the z distribution. Thus, we can treat the t-value as a z-value, essentially assuming infinite degrees of freedom.</p>
<p>Here, we look up the <em>p</em>-value that matches the absolute (non-signed) <em>t</em>-value for our parameters in the normal distribution. Then we subtract that value from 1 to get the probability of a <em>t</em>-value exceeding the one we have, and multiply that by 2 to get a two-tailed <em>p</em>-value.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lexdec_mod %&gt;%<span class="st"> </span>
<span class="st">  </span>broom::<span class="kw">tidy</span>(<span class="st">&quot;fixed&quot;</span>) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">p_value =</span> <span class="dv">2</span>*(<span class="dv">1</span> -<span class="st"> </span><span class="kw">pnorm</span>(<span class="kw">abs</span>(statistic))))</code></pre></div>
<pre><code>##          term   estimate  std.error  statistic     p_value
## 1 (Intercept)  6.3850897 0.02983012 214.048401 0.000000000
## 2      lang_c -0.1558212 0.05769542  -2.700755 0.006918227</code></pre>
<p>Just be aware that this approach somewhat inflates type-I error rates (but only slightly so with large samples).</p>
<p>Another alternative we can use to assess whether we have a main effect of a factor with multiple levels is to use a model comparisons approach, which we’ll look at next.</p>
</div>
<div id="model-selection" class="section level3">
<h3><span class="header-section-number">9.4.2</span> Model Selection</h3>
<p>With the model comparisons approach, we simply fit our full model, and a model that is exactly the same as the full model, only without the fixed effect of interest. Here, because we want to check for a main effect of language, we simply fit a model with only an intercept term (and without an effect of language). Notice that the random effects stay the same.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lexdec_mod_reduced &lt;-<span class="st"> </span><span class="kw">lmer</span>(RT ~<span class="st"> </span><span class="dv">1</span> +<span class="st"> </span>(<span class="dv">1</span> |<span class="st"> </span>Subject) +<span class="st"> </span>(<span class="dv">1</span> |<span class="st"> </span>Word), <span class="dt">data =</span> lex_dec, <span class="dt">REML =</span> F)</code></pre></div>
<p>Then, we use the <code>anova()</code> function to check whether inclusion of the language fixed factor significantly improves model fit. Notice also that if we originally fit our models with REML, R will refit them with ML instead.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(lexdec_mod, lexdec_mod_reduced)</code></pre></div>
<pre><code>## Data: lex_dec
## Models:
## lexdec_mod_reduced: RT ~ 1 + (1 | Subject) + (1 | Word)
## lexdec_mod: RT ~ lang_c + (1 | Subject) + (1 | Word)
##                    Df     AIC     BIC logLik deviance  Chisq Chi Df
## lexdec_mod_reduced  4 -895.86 -874.20 451.93  -903.86              
## lexdec_mod          5 -900.12 -873.05 455.06  -910.12 6.2605      1
##                    Pr(&gt;Chisq)  
## lexdec_mod_reduced             
## lexdec_mod            0.01235 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Here, we’re interested in the change in log-likelihood when we add terms to our model. Here, the increase in degrees of freedom should be one for each model you compare. We can see that adding the fixed effect of language significantly improved model fit, <span class="math inline">\(\chi^2(1) = 6.261, p = 0.012\)</span>. This means that we have a significant main effect of language.</p>
<p>We can similarly use this method to assess whether or not we should include random effects in our model, however whether or not you should select your random effects on the fly is again up for debate.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lexdec_slope &lt;-<span class="st"> </span><span class="kw">lmer</span>(RT ~<span class="st"> </span>lang_c +<span class="st"> </span>(<span class="dv">1</span> |<span class="st"> </span>Subject) +<span class="st"> </span>(lang_c ||<span class="st"> </span>Word), <span class="dt">data =</span> lex_dec, <span class="dt">REML =</span> F)
lexdec_slope_cov &lt;-<span class="st"> </span><span class="kw">lmer</span>(RT ~<span class="st"> </span>lang_c +<span class="st"> </span>(<span class="dv">1</span> |<span class="st"> </span>Subject) +<span class="st"> </span>(lang_c |<span class="st"> </span>Word), <span class="dt">data =</span> lex_dec, <span class="dt">REML =</span> F)
<span class="kw">anova</span>(lexdec_mod, lexdec_slope, lexdec_slope_cov)</code></pre></div>
<pre><code>## Data: lex_dec
## Models:
## lexdec_mod: RT ~ lang_c + (1 | Subject) + (1 | Word)
## lexdec_slope: RT ~ lang_c + (1 | Subject) + ((1 | Word) + (0 + lang_c | Word))
## lexdec_slope_cov: RT ~ lang_c + (1 | Subject) + (lang_c | Word)
##                  Df     AIC     BIC logLik deviance   Chisq Chi Df
## lexdec_mod        5 -900.12 -873.05 455.06  -910.12               
## lexdec_slope      6 -903.05 -870.57 457.53  -915.05  4.9348      1
## lexdec_slope_cov  7 -921.40 -883.51 467.70  -935.40 20.3514      1
##                  Pr(&gt;Chisq)    
## lexdec_mod                     
## lexdec_slope        0.02632 *  
## lexdec_slope_cov  6.445e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>To understand what happened here, we need to look at our random effects. Look at the summary of the model with only random intercepts by subject and item. You can see that the random effects here are calculated for the intercept terms and for the residuals.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(lexdec_mod)</code></pre></div>
<pre><code>## Linear mixed model fit by maximum likelihood  [&#39;lmerMod&#39;]
## Formula: RT ~ lang_c + (1 | Subject) + (1 | Word)
##    Data: lex_dec
## 
##      AIC      BIC   logLik deviance df.resid 
##   -900.1   -873.0    455.1   -910.1     1654 
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -2.3600 -0.6142 -0.1196  0.4614  5.9658 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  Word     (Intercept) 0.005896 0.07678 
##  Subject  (Intercept) 0.016742 0.12939 
##  Residual             0.029842 0.17275 
## Number of obs: 1659, groups:  Word, 79; Subject, 21
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)  6.38509    0.02983   214.1
## lang_c      -0.15582    0.05770    -2.7
## 
## Correlation of Fixed Effects:
##        (Intr)
## lang_c 0.000</code></pre>
<p>Look at the next model, with random slopes added. Here, we use the double pipe (<code>||</code>) in our random effects to specify that we want random intercepts and slopes, but we don’t want to calculate the intercept-slope covariance. (But, note that this only works for numeric, continuous predictors; centering again helps here.) This can be seen in our random effects where we have <code>Word lang_c</code> which shows the slope for language by item, <code>Word.1 (Intercept)</code> which is the intercept for items, and <code>Subject (Intercept)</code> which shows the intercept for the subjects.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(lexdec_slope)</code></pre></div>
<pre><code>## Linear mixed model fit by maximum likelihood  [&#39;lmerMod&#39;]
## Formula: RT ~ lang_c + (1 | Subject) + ((1 | Word) + (0 + lang_c | Word))
##    Data: lex_dec
## 
##      AIC      BIC   logLik deviance df.resid 
##   -903.1   -870.6    457.5   -915.1     1653 
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -2.5314 -0.6105 -0.1222  0.4714  6.0190 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  Word     lang_c      0.002351 0.04849 
##  Word.1   (Intercept) 0.005925 0.07697 
##  Subject  (Intercept) 0.016757 0.12945 
##  Residual             0.029237 0.17099 
## Number of obs: 1659, groups:  Word, 79; Subject, 21
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)  6.38509    0.02984  213.96
## lang_c      -0.15582    0.05797   -2.69
## 
## Correlation of Fixed Effects:
##        (Intr)
## lang_c 0.000</code></pre>
<p>Finally, if we look at the more complex model, we can see that we have intercepts and slopes for the items, and we’ve calculated the covariance between these terms (in the <code>Corr</code> column.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(lexdec_slope_cov)</code></pre></div>
<pre><code>## Linear mixed model fit by maximum likelihood  [&#39;lmerMod&#39;]
## Formula: RT ~ lang_c + (1 | Subject) + (lang_c | Word)
##    Data: lex_dec
## 
##      AIC      BIC   logLik deviance df.resid 
##   -921.4   -883.5    467.7   -935.4     1652 
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -2.6132 -0.6175 -0.1112  0.4677  6.1894 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev. Corr 
##  Word     (Intercept) 0.005924 0.07697       
##           lang_c      0.002349 0.04846  -0.98
##  Subject  (Intercept) 0.016756 0.12944       
##  Residual             0.029237 0.17099       
## Number of obs: 1659, groups:  Word, 79; Subject, 21
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)  6.38509    0.02984  213.97
## lang_c      -0.15582    0.05796   -2.69
## 
## Correlation of Fixed Effects:
##        (Intr)
## lang_c -0.027</code></pre>
<p>It seems that this model better explains our data than the other models, so we should probably use this one. Still, the choice of random effects structure can be as much driven by your assumptions and knowledge of the source of the data as from these data driven techniques.</p>
</div>
<div id="failure-to-converge-what-should-i-do" class="section level3">
<h3><span class="header-section-number">9.4.3</span> Failure to Converge: What Should I Do?</h3>
<p>Often, when you attempt to fit the maximal random effects structure you will get an error saying that your model failed to converge. This means that you don’t have enough information in your data (or your data is so noisy) that you cannot properly identify the full variance covariance matrix for the model. This happens a lot if you have variances that are equal or nearly equal to 0, or correlations in terms that are equal to -1 or 1.</p>
<p>One way to avoid problems with converging is to centre your factors (as we have done above) and use numeric predictors in your model. You can also try to use a different optimiser by specifying the options in <code>lme4</code>. You can specify your optimiser like so. Check out the summaries of these models to see how they differ. Basically, these optimisers are just different methods for attempting to find the best fitting model for your data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">nelder_mod &lt;-<span class="st"> </span><span class="kw">lmer</span>(
  RT ~<span class="st"> </span>lang_c +<span class="st"> </span>(<span class="dv">1</span> |<span class="st"> </span>Subject) +<span class="st"> </span>(lang_c |<span class="st"> </span>Word), 
  <span class="dt">data =</span> lex_dec, <span class="dt">REML =</span> F, 
  <span class="dt">control =</span> <span class="kw">lmerControl</span>(<span class="dt">optimizer =</span> <span class="st">&quot;Nelder_Mead&quot;</span>)
  )
boby_mod &lt;-<span class="st"> </span><span class="kw">lmer</span>(
  RT ~<span class="st"> </span>lang_c +<span class="st"> </span>(<span class="dv">1</span> |<span class="st"> </span>Subject) +<span class="st"> </span>(lang_c |<span class="st"> </span>Word), 
  <span class="dt">data =</span> lex_dec, <span class="dt">REML =</span> F, 
  <span class="dt">control =</span> <span class="kw">lmerControl</span>(<span class="dt">optimizer =</span> <span class="st">&quot;bobyqa&quot;</span>)
     )</code></pre></div>
<p>Also, if you have complex models, with intercepts and slopes calculated for subjects and items for something that is also a fixed effect, your model can effectively run out of the degrees of freedom to estimate the correlations between your intercepts and slopes. One work around here is to just simplify your model. There are a number of suggestions for how you should do this.</p>
<p>In psychological research, <a href="https://hlplab.wordpress.com/2009/05/14/random-effect-structure/">one suggested procedure</a> is as follows:</p>
<p>For a model specified as <code>lmer(outcome ~ A * B + (1 + A * B | subjects) + (1 + A * B | items), data)</code>:</p>
<ul>
<li>First remove the correlations between random effects, i.e. <code>(1 + A + B | subjects) + (1 + A + B | items)</code></li>
<li>If that doesn’t converge, remove the by-items slopes for one factor (which explains the least variance) first. <code>(1 + A + B | subjects) + (1 + A | items)</code></li>
<li>If that doesn’t converge, remove the reamining by-items slopes <code>(1 + A + B | subjects) + (1 | items)</code></li>
<li>Remove slopes on subjects until it eventually converges</li>
</ul>
<p>The reasoning here is that in our experiments we attempt to control as many confounds in our items as possible, such that variance within items should be smaller than variance within subjects.</p>
<p>If your model doesn’t converge with random intercepts by both terms, you should probably explore your data for potential problems.</p>
</div>
</div>
<div id="test-assumptions" class="section level2">
<h2><span class="header-section-number">9.5</span> Test Assumptions</h2>
<p>While mixed effects models get around many of the stricter assumptions from linear models, these models still make some assumptions. Some assumptions you need to worry about include:</p>
<ul>
<li><p>Linearity: Unsurprisingly, linear models require linearly related data. You can check for this with a graph as in previous sections. Alternatively, you can fit a non-linear function to your model.</p></li>
<li><p>Independence: If your data are not independent (e.g. with multiple responses per participant) then your model must specify this is the case through your random effects. Failing to do so will lead to violations of this assumption, and incorrectly fitted models.</p></li>
<li><p>Normal Distribution of Random Coefficients: random coefficients are assumed to be normally distributed around the model. For random intercepts models this means that your intercepts are supposed to be normally distributed around the overall model (<span class="citation">A. Field, Miles, and Field (<a href="#ref-field2012discovering">2012</a>)</span>).</p></li>
<li><p>Multicollinearity: This is where one predictor in your model can be can be reasonably accurately linearly predicted from the other predictors in your model. You can check for this by using the <code>vif()</code> function from the <code>usdm</code> library. Centering your predictors can help with problems of multicollinearity.</p></li>
<li><p>Homoscedasticity: The error term in your model should be the same across all of your variables. You could use a Levene’s test or a plot of residuals vs. fitted values, as with regular linear models.</p></li>
<li><p>Outliers: Large outliers will skew your data. You can check for these using any traditional means, e.g. eye-balling your data via graphs or excluding based on some reasonable criteria (e.g. + 3SD above the mean). Just make sure you have a principled decision for excluding data.</p></li>
</ul>
</div>
<div id="generalised-mixed-effects-models" class="section level2">
<h2><span class="header-section-number">9.6</span> Generalised Mixed Effects Models</h2>
<p>Generalised mixed effects models are performed in a similar way to mixed effects models, but are applied to cases when your outcome or dependent variable is not normally distributed, e.g. logistic regression for binary response data. These models use the same logic as generalised linear models, and the interpretation is very similar to mixed effects models. However here the <em>p</em>-values are calculated for the fixed effects coefficients straight out of the model!</p>
<p>We implement these models for binary response data like so:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">glmer</span>(
  DV_binom ~<span class="st"> </span><span class="co"># binomial dependent variable</span>
<span class="st">    </span>A *<span class="st"> </span>B +<span class="st"> </span><span class="co"># fixed effects</span>
<span class="st">    </span>(A *<span class="st"> </span>B |<span class="st"> </span>subject) +<span class="st"> </span>(A *<span class="st"> </span>B |<span class="st"> </span>item), <span class="co"># random effects </span>
  <span class="dt">family =</span> binomial, <span class="co"># family: type of distribution</span>
  <span class="dt">data =</span> data, 
  <span class="kw">glmerControl</span>(<span class="dt">optimizer =</span> <span class="st">&quot;bobyqa&quot;</span>) <span class="co"># options; notice glmerControl (not lmer)</span>
  )</code></pre></div>
<p>For proportions, we simply set the weights of the model to the number of success and provide the proportions as our dependent variable.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">glmer</span>(
  DV_prop ~<span class="st"> </span><span class="co"># dependent variable as a proportion</span>
<span class="st">    </span>A *<span class="st"> </span>B +<span class="st"> </span><span class="co"># fixed effects</span>
<span class="st">    </span>(A *<span class="st"> </span>B |<span class="st"> </span>subject) +<span class="st"> </span>(A *<span class="st"> </span>B |<span class="st"> </span>item), <span class="co"># random effects </span>
  <span class="dt">family =</span> binomial, <span class="co"># family: type of distribution</span>
  <span class="dt">weights =</span> N_observations, <span class="co"># number of observations making up the proportion</span>
  <span class="dt">data =</span> data,
  <span class="kw">glmerControl</span>(<span class="dt">optimizer =</span> <span class="st">&quot;bobyqa&quot;</span>)<span class="co"># options; notice glmerControl (not lmer)</span>
  )</code></pre></div>
<p>Alternatively, we can calculate these within the model if we have the number of successes and the number of observations as columns in our model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">glmer</span>(
  DV_successes/N_observations ~<span class="st"> </span><span class="co"># calculate proportion</span>
<span class="st">    </span>A *<span class="st"> </span>B +<span class="st"> </span><span class="co"># fixed effects</span>
<span class="st">    </span>(A *<span class="st"> </span>B |<span class="st"> </span>subject) +<span class="st"> </span>(A *<span class="st"> </span>B |<span class="st"> </span>item), <span class="co"># random effects </span>
  <span class="dt">family =</span> binomial, <span class="co"># family: type of distribution</span>
  <span class="dt">weights =</span> N_observations, <span class="co"># number of observations making up the proportion</span>
  <span class="dt">data =</span> data,
  <span class="kw">glmerControl</span>(<span class="dt">optimizer =</span> <span class="st">&quot;bobyqa&quot;</span>) <span class="co"># options; notice glmerControl (not lmer)</span>
  )</code></pre></div>
<p>Here, our parameter estimates are interpreted as log likelihoods.</p>
</div>
<div id="a-note-on-power-effect-sizes-and-pairwise-comparisons" class="section level2">
<h2><span class="header-section-number">9.7</span> A Note on Power, Effect Sizes, and Pairwise Comparisons</h2>
<div id="power" class="section level3">
<h3><span class="header-section-number">9.7.1</span> Power</h3>
<p>Power analysis is rather complex for mixed effects models. Here, simulation is key, and there are some packages out there to help you perform your own power analyses with little coding, such as SIMR (<code>install.packages(&quot;simr&quot;)</code>). You can find a paper on <a href="https://besjournals.onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.12504">how to use SIMR here</a>.</p>
</div>
<div id="effect-sizes" class="section level3">
<h3><span class="header-section-number">9.7.2</span> Effect Sizes</h3>
<p>Effect sizes for individual parameter estimates and/or the entire model fit are often not reported with mixed effects models due to the practical and/or technical difficulties posed by calculating effect sizes. However, there are some options out there, such as that offered by the <code>r2beta()</code> function from the <strong>r2glmm package</strong>, or the <code>r.squaredGLMM()</code> function from the <strong>MuMIn package</strong>. I’ll leave it up to you to explore these options, but we might return to this in the final lesson.</p>
</div>
<div id="pairwise-comparisons" class="section level3">
<h3><span class="header-section-number">9.7.3</span> Pairwise Comparisons</h3>
<p>Pairwise comparisons can be conducted in the same way as for linear models. You can either subset your data to the a single level of one factor to explore the simple effects for another factor, adjusting your <em>p</em>-values manually in the process, or you can use the <code>glht()</code> function from the <strong>multcomp</strong> package.</p>
</div>
</div>
<div id="exercises-8" class="section level2">
<h2><span class="header-section-number">9.8</span> Exercises</h2>
<p>For these exercises, we will look at the core concepts from this lesson. Here, you’ll make your own data using simulation-based techniques, and you’ll use those same techniques to calculate power for your design.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)
<span class="kw">library</span>(lme4)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dat &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;inputs/factorial_data.csv&quot;</span>)</code></pre></div>
<div id="question-1-8" class="section level3">
<h3><span class="header-section-number">9.8.1</span> Question 1</h3>
<p>Summarise the data, creating means, standard deviations, and ns for each group in the data set.</p>
</div>
<div id="question-2-8" class="section level3">
<h3><span class="header-section-number">9.8.2</span> Question 2</h3>
<p>Centre the factors A and B in preparation for fitting the model. Define the centred variables for A and B as <strong>A_c</strong> and <strong>B_c</strong> respectively. Return the data set to see what you did to the data frame.</p>
</div>
<div id="question-3-8" class="section level3">
<h3><span class="header-section-number">9.8.3</span> Question 3</h3>
<ol style="list-style-type: lower-alpha">
<li>Find maximal random effects structure for the model and call this <strong>maximal_model</strong>. Return the a summary of the model output when you’re done. Assume that the data from which this is taken is not nested. This model may take a while to fit, so be patient!</li>
<li>Where is most of the variance explained? What does this tell us about the model (i.e. is it overfitting the data)?</li>
<li>Are there any perfect correlations between the random effects? What does this tell us about our random effects structure?</li>
</ol>
</div>
<div id="question-4-8" class="section level3">
<h3><span class="header-section-number">9.8.4</span> Question 4</h3>
<p>Explore the whether inclusion of the interaction significantly improves model fit over a model with just main effects. Be sure to include all random effects in all models.</p>
</div>
<div id="question-5-8" class="section level3">
<h3><span class="header-section-number">9.8.5</span> Question 5</h3>
<p>Calculate <em>p</em>-values for the parameters in your maximal model (including interactions) using the normal approximation. Round each number to 2 decimal places.</p>
</div>
<div id="question-6-8" class="section level3">
<h3><span class="header-section-number">9.8.6</span> Question 6</h3>
<p>Explore the interaction by subsetting the data to each level of factor A and fitting a model containing factor B. Then do the same for the remaining factor. Where does the interaction lie?</p>
<p>First, subset the data as described above, and assign this to four objects called A1_dat, A2_dat, B1_dat, and B2_dat respectively.</p>
<p>Then, fit four models looking at the main effect of one factor within each subset of data.</p>
<p>Next, extract a tidied version of the coefficients from each model and add a column identifying which comparison these models are from. Assign these to A1_comp, A2_comp, B1_comp and B2_comp respectively, showing that these objects contain the comparisons for each level.</p>
<p>Finally, bind the rows together from your comparisons, and create a <em>p</em>-value for your data using the normal approximation. Be sure to bonferroni correct your data. After the correction, make sure that you reset any <em>p</em>-values above 1 to 1 (as <em>p</em>-values above 1 don’t make any sense).</p>
</div>
<div id="question-7-7" class="section level3">
<h3><span class="header-section-number">9.8.7</span> Question 7</h3>
<p>Make a plot showing the interaction between A and B.</p>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-field2012discovering">
<p>Field, Andy, Jeremy Miles, and Zoë Field. 2012. <em>Discovering Statistics Using R</em>. Sage publications.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="simulation-and-calculating-power.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="creating-reproducible-documents.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
